{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb4a35-5758-4e49-be8e-3e908816027b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4b1ee-171e-4fb0-bb92-c047a469e79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca86de-8a65-4c43-8ca3-9aac675f1cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f50397-5c38-4733-b2ad-d6133887163e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a8fee3-0e88-4f38-8941-b3161a53ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Block 1: Imports + Config + Normalization Helpers\n",
    "# =========================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG: file paths (edit if your filenames differ)\n",
    "# You can override any of these using environment variables with the same names.\n",
    "# -------------------------\n",
    "P1_FILE = os.getenv(\"P1_FILE\", \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt1/dbpedia/ont_12_monument_output.jsonl\")  # Prompt 1 outputs\n",
    "P2_FILE = os.getenv(\"P2_FILE\", \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt2/dbpedia/ont_12_monument_output.jsonl\")  # Prompt 2 outputs\n",
    "P3_FILE = os.getenv(\"P3_FILE\", \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_12_monument_output.jsonl\")  # Prompt 3 outputs\n",
    "ONT_FILE = os.getenv(\"ONT_FILE\", \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/12_monument_ontology.json\")  # Ontology (authority)\n",
    "GT_FILE  = os.getenv(\"GT_FILE\",  \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_12_monument_ground_truth.jsonl\")  # Optional: for metrics only\n",
    "\n",
    "# -------------------------\n",
    "# Normalization helpers (strings, keys) — NO date detection/normalization\n",
    "# -------------------------\n",
    "\n",
    "_WHITESPACE_RE = re.compile(r\"\\s+\")\n",
    "_QUOTES_TO_STRIP = \"“”\\\"'`’\"\n",
    "\n",
    "def norm_surface(s: Any) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a surface string for display/storage (light touch).\n",
    "    - convert non-strings with json.dumps to preserve structure\n",
    "    - strip surrounding quotes\n",
    "    - collapse internal whitespace\n",
    "    \"\"\"\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = json.dumps(s, ensure_ascii=False)\n",
    "    t = s.strip().strip(_QUOTES_TO_STRIP)\n",
    "    t = _WHITESPACE_RE.sub(\" \", t)\n",
    "    return t\n",
    "\n",
    "def norm_key(s: Any) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a string for equality comparisons across prompts.\n",
    "    - convert non-strings with json.dumps to preserve structure\n",
    "    - strip surrounding quotes\n",
    "    - collapse internal whitespace\n",
    "    - lowercase\n",
    "    \"\"\"\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = json.dumps(s, ensure_ascii=False)\n",
    "    t = s.strip().strip(_QUOTES_TO_STRIP)\n",
    "    t = _WHITESPACE_RE.sub(\" \", t)\n",
    "    return t.lower()\n",
    "\n",
    "def canonical_triple_key(subj: Any, rel: Any, obj: Any) -> Tuple[str, str, str]:\n",
    "    \"\"\"\n",
    "    Build a normalized key for comparing triples across prompts.\n",
    "    NO date parsing. Object is treated as plain text.\n",
    "    - subject & relation: norm_key\n",
    "    - object: norm_surface → norm_key\n",
    "    \"\"\"\n",
    "    s = norm_key(subj)\n",
    "    r = norm_key(rel)\n",
    "    o = norm_key(norm_surface(obj))\n",
    "    return (s, r, o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a20c84-3c40-4af5-8eb3-45cb65dc30dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaded] ids=19 | triples: p1=0, p2=59, p3=57 | total=116\n",
      "Sample ID: ont_12_monument_test_1\n",
      "  p1 triples: 0\n",
      "  p2 triples: 3\n",
      "  p3 triples: 3\n",
      "  example triple from p2 : {'s': 'The 14th New Jersey Volunteer Infantry Monument', 'p': 'location', 'o': 'Monocacy National Battlefield', 'confidence': 1.0, 'support_text': 'which is located in the Monocacy National Battlefield', 'source_prompt': 'P2', 'canonical': ('the 14th new jersey volunteer infantry monument', 'location', 'monocacy national battlefield')}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Block 2: Loaders + Per-ID Index (no ontology)\n",
    "# =========================\n",
    "# Purpose:\n",
    "#   - Read P1/P2/P3 JSONL outputs safely.\n",
    "#   - Normalize heterogeneous triple schemas into a common internal shape.\n",
    "#   - Attach provenance (which prompt/file, source line).\n",
    "#   - Preserve the common `input text` per id.\n",
    "#   - Build a per-id index: {id: {\"input_text\": str|None, \"p1\":[...], \"p2\":[...], \"p3\":[...]}}\n",
    "#   - (No ontology logic here; no date parsing — handled by Block 1 normalizers only.)\n",
    "#\n",
    "# Notes:\n",
    "#   - This block depends on Block 1 helpers: norm_surface, norm_key, canonical_triple_key\n",
    "#   - We DO NOT change the evaluator rules here; we just prepare clean data for Block 3.\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "import re\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "# -------------------------\n",
    "# 1) JSONL reader (strict JSON; keeps parse errors as rows with _parse_error)\n",
    "# -------------------------\n",
    "def read_jsonl(path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Read a JSONL file into a list of row dicts.\n",
    "    - On parse errors, inject a row with _parse_error and the raw prefix.\n",
    "    - If the file is missing, return [] and print a warning.\n",
    "    \"\"\"\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for ln, line in enumerate(f, start=1):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    obj = json.loads(line)\n",
    "                    obj[\"_line_no\"] = ln\n",
    "                    rows.append(obj)\n",
    "                except Exception as e:\n",
    "                    rows.append({\n",
    "                        \"_line_no\": ln,\n",
    "                        \"_parse_error\": str(e),\n",
    "                        \"_raw\": line[:500],\n",
    "                    })\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[WARN] File not found: {path}\")\n",
    "    return rows\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 2) Support coercion helpers\n",
    "# -------------------------\n",
    "def _extract_support_text(triple_obj: Dict[str, Any]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Return a unified support text string:\n",
    "      - P1/P2: support is a string: return as-is (normalized lightly by caller if needed).\n",
    "      - P3: support is a list of {quote, char_span}; concatenate all quotes with ' | '.\n",
    "      - If support is missing/empty, return None.\n",
    "    \"\"\"\n",
    "    sup = triple_obj.get(\"support\")\n",
    "    if sup is None:\n",
    "        return None\n",
    "\n",
    "    # P3 style: list of dicts with \"quote\"\n",
    "    if isinstance(sup, list):\n",
    "        quotes = []\n",
    "        for item in sup:\n",
    "            if isinstance(item, dict):\n",
    "                q = item.get(\"quote\")\n",
    "                if isinstance(q, str) and q.strip():\n",
    "                    quotes.append(q.strip())\n",
    "            elif isinstance(item, str) and item.strip():\n",
    "                # be tolerant if it's already strings\n",
    "                quotes.append(item.strip())\n",
    "        return \" | \".join(quotes) if quotes else None\n",
    "\n",
    "    # P1/P2 style: single string\n",
    "    if isinstance(sup, str):\n",
    "        s = sup.strip()\n",
    "        return s if s else None\n",
    "\n",
    "    # Unknown shape → None\n",
    "    return None\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3) STRICT extractor (response -> json -> triples), with provenance & normalization\n",
    "# -------------------------\n",
    "def extract_triples_strict(row: Dict[str, Any], file_tag: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Expect fixed schema per pipeline: row[\"response\"][\"json\"][\"triples\"] -> list\n",
    "    Normalize heterogeneous triple dicts into a common internal representation:\n",
    "      {\n",
    "        \"s\": <subject original surface>,\n",
    "        \"p\": <relation original surface>,\n",
    "        \"o\": <object original surface>,\n",
    "        \"confidence\": <float|None>,\n",
    "        \"support_raw\": <original support field>,\n",
    "        \"support_text\": <coerced string or None>,\n",
    "        \"source_prompt\": <file_tag>,\n",
    "        \"canonical\": (s_norm, p_norm, o_norm)  # via Block 1 canonical_triple_key\n",
    "      }\n",
    "    If schema missing/invalid → return [].\n",
    "    \"\"\"\n",
    "    resp = row.get(\"response\")\n",
    "    if not isinstance(resp, dict):\n",
    "        return []\n",
    "    js = resp.get(\"json\")\n",
    "    if not isinstance(js, dict):\n",
    "        return []\n",
    "    triples = js.get(\"triples\")\n",
    "    if not isinstance(triples, list):\n",
    "        return []\n",
    "\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    for t in triples:\n",
    "        if not isinstance(t, dict):\n",
    "            continue\n",
    "\n",
    "        # Expected shape has \"triple\": [\"s\",\"p\",\"o\"]\n",
    "        spo = t.get(\"triple\")\n",
    "        if not (isinstance(spo, list) and len(spo) == 3):\n",
    "            continue\n",
    "\n",
    "        s_raw, p_raw, o_raw = spo[0], spo[1], spo[2]\n",
    "        # Keep originals as-is for output\n",
    "        s = s_raw if isinstance(s_raw, str) else norm_surface(s_raw)\n",
    "        p = p_raw if isinstance(p_raw, str) else norm_surface(p_raw)\n",
    "        o = o_raw if isinstance(o_raw, str) else norm_surface(o_raw)\n",
    "\n",
    "        # Confidence (optional)\n",
    "        conf = t.get(\"confidence\")\n",
    "        try:\n",
    "            conf = float(conf) if conf is not None else None\n",
    "        except Exception:\n",
    "            conf = None\n",
    "\n",
    "        support_text = _extract_support_text(t)\n",
    "\n",
    "        triple_norm_key = canonical_triple_key(s, p, o)\n",
    "\n",
    "        out.append({\n",
    "            \"s\": s,\n",
    "            \"p\": p,\n",
    "            \"o\": o,\n",
    "            \"confidence\": conf,\n",
    "            \"support_raw\": t.get(\"support\"),\n",
    "            \"support_text\": support_text,\n",
    "            \"source_prompt\": file_tag,\n",
    "            \"canonical\": triple_norm_key,\n",
    "        })\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 4) Load one prompt file into a per-id store\n",
    "# -------------------------\n",
    "def _pick_input_text(existing: Optional[str], candidate_row: Dict[str, Any]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Choose the non-empty 'input text' if available;\n",
    "    keep the first non-empty value we encounter across rows.\n",
    "    Accept both 'input text' and 'input_text' keys (be tolerant).\n",
    "    \"\"\"\n",
    "    if existing and existing.strip():\n",
    "        return existing\n",
    "    # Prefer exact key 'input text' (as in your sample)\n",
    "    txt = candidate_row.get(\"input text\")\n",
    "    if isinstance(txt, str) and txt.strip():\n",
    "        return txt\n",
    "    # Fallback variants\n",
    "    for k in (\"input_text\", \"input\", \"text\", \"source_text\"):\n",
    "        v = candidate_row.get(k)\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            return v\n",
    "    return existing  # unchanged (possibly None)\n",
    "\n",
    "\n",
    "def load_prompt_outputs_strict(path: str, file_tag: str) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Read a prompt JSONL file and produce:\n",
    "      {\n",
    "        id: {\n",
    "          \"input_text\": str|None,\n",
    "          \"rows\":   [raw rows without parse errors],\n",
    "          \"triples\":[normalized triple dicts with provenance]\n",
    "        },\n",
    "        ...\n",
    "      }\n",
    "    - Skips rows with _parse_error.\n",
    "    - Aggregates triples across multiple rows for the same id.\n",
    "    \"\"\"\n",
    "    data: Dict[str, Dict[str, Any]] = {}\n",
    "    rows = read_jsonl(path)\n",
    "\n",
    "    for row in rows:\n",
    "        if row.get(\"_parse_error\"):\n",
    "            continue\n",
    "        rid = row.get(\"id\")\n",
    "        if not rid:\n",
    "            # Skip rows without id\n",
    "            continue\n",
    "\n",
    "        bucket = data.setdefault(rid, {\"input_text\": None, \"rows\": [], \"triples\": []})\n",
    "        bucket[\"rows\"].append(row)\n",
    "\n",
    "        # Update/keep the common input_text\n",
    "        bucket[\"input_text\"] = _pick_input_text(bucket[\"input_text\"], row)\n",
    "\n",
    "        # Extract triples\n",
    "        triples = extract_triples_strict(row, file_tag)\n",
    "        if triples:\n",
    "            bucket[\"triples\"].extend(triples)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 5) Dedup helper (per list of triples)\n",
    "# -------------------------\n",
    "def dedup_triples(triples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Deduplicate triples by their canonical (s,p,o) key.\n",
    "    Keep the first occurrence (preserves a representative confidence/support/source).\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    for t in triples:\n",
    "        k = t.get(\"canonical\")\n",
    "        if not k:\n",
    "            # If canonical missing, compute on the fly (defensive)\n",
    "            k = canonical_triple_key(t.get(\"s\"), t.get(\"p\"), t.get(\"o\"))\n",
    "            t[\"canonical\"] = k\n",
    "        if k in seen:\n",
    "            continue\n",
    "        seen.add(k)\n",
    "        out.append(t)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 6) Build per-ID unified view across prompts\n",
    "# -------------------------\n",
    "def build_id_index(P1: Dict[str, Dict[str, Any]],\n",
    "                   P2: Dict[str, Dict[str, Any]],\n",
    "                   P3: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Combine three per-id maps (from load_prompt_outputs_strict) into:\n",
    "      {\n",
    "        id: {\n",
    "          \"input_text\": first-nonempty among P1,P2,P3,\n",
    "          \"p1\": [triples...],  # deduped\n",
    "          \"p2\": [triples...],  # deduped\n",
    "          \"p3\": [triples...],  # deduped\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "    ids = sorted(set(P1.keys()) | set(P2.keys()) | set(P3.keys()),\n",
    "                 key=lambda x: int(re.findall(r'\\d+$', x)[0]) if re.findall(r'\\d+$', x) else x)\n",
    "\n",
    "    out: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    for rid in ids:\n",
    "        input_text = None\n",
    "        for src in (P1.get(rid), P2.get(rid), P3.get(rid)):\n",
    "            if src:\n",
    "                input_text = _pick_input_text(input_text, {\"input text\": src.get(\"input_text\")})\n",
    "                # _pick_input_text expects a row-like dict; we adapt here by keying to \"input text\"\n",
    "\n",
    "        p1_tr = dedup_triples(P1.get(rid, {}).get(\"triples\", []))\n",
    "        p2_tr = dedup_triples(P2.get(rid, {}).get(\"triples\", []))\n",
    "        p3_tr = dedup_triples(P3.get(rid, {}).get(\"triples\", []))\n",
    "\n",
    "        out[rid] = {\n",
    "            \"input_text\": input_text,\n",
    "            \"p1\": p1_tr,\n",
    "            \"p2\": p2_tr,\n",
    "            \"p3\": p3_tr,\n",
    "        }\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 7) Summary printer\n",
    "# -------------------------\n",
    "def summarize_loaded(index_by_id: Dict[str, Dict[str, Any]]) -> None:\n",
    "    \"\"\"\n",
    "    Print a concise summary of loaded content: number of ids and triple counts per prompt.\n",
    "    \"\"\"\n",
    "    total_ids = len(index_by_id)\n",
    "    p1 = sum(len(b[\"p1\"]) for b in index_by_id.values())\n",
    "    p2 = sum(len(b[\"p2\"]) for b in index_by_id.values())\n",
    "    p3 = sum(len(b[\"p3\"]) for b in index_by_id.values())\n",
    "    print(f\"[Loaded] ids={total_ids} | triples: p1={p1}, p2={p2}, p3={p3} | total={p1+p2+p3}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 8) Execute loads (strict) using paths from Block 1\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load each prompt's outputs with provenance\n",
    "    P1 = load_prompt_outputs_strict(P1_FILE, \"P1\")\n",
    "    P2 = load_prompt_outputs_strict(P2_FILE, \"P2\")\n",
    "    P3 = load_prompt_outputs_strict(P3_FILE, \"P3\")\n",
    "\n",
    "    # Build cross-prompt index\n",
    "    INDEX_BY_ID = build_id_index(P1, P2, P3)\n",
    "    summarize_loaded(INDEX_BY_ID)\n",
    "\n",
    "    # Quick peek at one id\n",
    "    SAMPLE_ID = next(iter(INDEX_BY_ID)) if INDEX_BY_ID else None\n",
    "    print(\"Sample ID:\", SAMPLE_ID)\n",
    "    if SAMPLE_ID:\n",
    "        for tag in (\"p1\", \"p2\", \"p3\"):\n",
    "            print(f\"  {tag} triples:\", len(INDEX_BY_ID[SAMPLE_ID][tag]))\n",
    "        # Show one example triple (any prompt)\n",
    "        for tag in (\"p1\", \"p2\", \"p3\"):\n",
    "            if INDEX_BY_ID[SAMPLE_ID][tag]:\n",
    "                ex = INDEX_BY_ID[SAMPLE_ID][tag][0]\n",
    "                print(\"  example triple from\", tag, \":\", {\n",
    "                    \"s\": ex[\"s\"], \"p\": ex[\"p\"], \"o\": ex[\"o\"],\n",
    "                    \"confidence\": ex[\"confidence\"],\n",
    "                    \"support_text\": ex[\"support_text\"],\n",
    "                    \"source_prompt\": ex[\"source_prompt\"],\n",
    "                    \"canonical\": ex[\"canonical\"],\n",
    "                })\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ad2662c-7608-47e1-b182-116c76e4ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Block 3: Evaluator (Consensus + Evidence Scoring)\n",
    "# =========================\n",
    "# Purpose:\n",
    "#   - Select the best triples per ID from P1, P2, P3 according to your rules.\n",
    "#   - Rule A: consensus (same canonical s,p,o) appears in ≥2 prompts + subj/obj in input text (fuzzy ≥ 0.90).\n",
    "#   - Rule B: single-prompt with evidence (support required), Evidence = 0.50*COLOC + 0.25*SUBJ_SUP + 0.25*OBJ_SUP + 0.10*SIM > 0.70.\n",
    "#   - NO synonym mapping (e.g., \"US\" != \"United States\" unless fuzzy ≥ 0.90 vs input text).\n",
    "#   - Outputs JSONL: {\"id\":\"...\",\"input_text\":\"...\",\"triples\":[{\"s\":\"...\",\"p\":\"...\",\"o\":\"...\"}]} ; if none → \"triples\": null\n",
    "#   - Includes a debug mode to inspect the first N IDs with detailed reasoning per triple.\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "import re\n",
    "import difflib\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "\n",
    "# ---------- Matching & Similarity Helpers ----------\n",
    "\n",
    "_WS_RE = re.compile(r\"\\s+\")\n",
    "_TOKEN_RE = re.compile(r\"\\w+\", flags=re.UNICODE)\n",
    "\n",
    "def _norm_for_match(s: Optional[str]) -> str:\n",
    "    \"\"\"Lowercase and collapse whitespace for fuzzy/substring checks.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    t = s.strip().lower()\n",
    "    t = _WS_RE.sub(\" \", t)\n",
    "    return t\n",
    "\n",
    "def _tokens(s: str) -> List[str]:\n",
    "    \"\"\"Tokenize to word tokens (letters/digits/underscore).\"\"\"\n",
    "    return _TOKEN_RE.findall(_norm_for_match(s))\n",
    "\n",
    "def jaccard_similarity(a: str, b: str) -> float:\n",
    "    \"\"\"\n",
    "    Jaccard similarity over token sets between two strings.\n",
    "    - If both token sets are empty → 0.0\n",
    "    \"\"\"\n",
    "    ta, tb = set(_tokens(a)), set(_tokens(b))\n",
    "    if not ta and not tb:\n",
    "        return 0.0\n",
    "    if not ta or not tb:\n",
    "        return 0.0\n",
    "    inter = len(ta & tb)\n",
    "    union = len(ta | tb)\n",
    "    return inter / union if union else 0.0\n",
    "\n",
    "def fuzzy_in(needle: str, haystack: str, threshold: float = 0.90) -> Tuple[bool, float]:\n",
    "    \"\"\"\n",
    "    Substring-aware fuzzy membership:\n",
    "      - True if normalized 'needle' is a literal substring of normalized 'haystack'.\n",
    "      - Else compute best difflib ratio over sliding token windows of haystack\n",
    "        with window sizes len(needle_tokens) .. len(needle_tokens)+2.\n",
    "      - Returns (bool_passed, best_score).\n",
    "    \"\"\"\n",
    "    n = _norm_for_match(needle)\n",
    "    h = _norm_for_match(haystack)\n",
    "    if not n or not h:\n",
    "        return (False, 0.0)\n",
    "\n",
    "    if n in h:\n",
    "        return (True, 1.0)\n",
    "\n",
    "    n_tokens = _tokens(n)\n",
    "    h_tokens = _tokens(h)\n",
    "\n",
    "    # Fallback: global ratio if tokens missing\n",
    "    if not n_tokens or not h_tokens:\n",
    "        score = difflib.SequenceMatcher(None, h, n).ratio()\n",
    "        return (score >= threshold, score)\n",
    "\n",
    "    best = 0.0\n",
    "    win_min = max(1, len(n_tokens))\n",
    "    win_max = min(len(h_tokens), len(n_tokens) + 2)\n",
    "    for w in range(win_min, win_max + 1):\n",
    "        for i in range(0, len(h_tokens) - w + 1):\n",
    "            seg = \" \".join(h_tokens[i:i + w])\n",
    "            r = difflib.SequenceMatcher(None, seg, n).ratio()\n",
    "            if r > best:\n",
    "                best = r\n",
    "            if best >= 1.0:\n",
    "                break\n",
    "        if best >= 1.0:\n",
    "            break\n",
    "\n",
    "    # If nothing matched well in windows, try a global ratio as a last resort\n",
    "    if best < threshold:\n",
    "        global_r = difflib.SequenceMatcher(None, h, n).ratio()\n",
    "        best = max(best, global_r)\n",
    "\n",
    "    return (best >= threshold, best)\n",
    "\n",
    "# ---------- Rule A & Rule B Evaluation ----------\n",
    "\n",
    "def _choose_surface_variant(instances: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Given multiple instances of the same canonical triple (from different prompts),\n",
    "    choose one representative triple to output.\n",
    "    - Prefer highest confidence; if None, treat as 0.0.\n",
    "    - If tie, keep the first.\n",
    "    \"\"\"\n",
    "    def conf_or_zero(x):\n",
    "        c = x.get(\"confidence\")\n",
    "        try:\n",
    "            return float(c) if c is not None else 0.0\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    best = max(instances, key=conf_or_zero)\n",
    "    return best\n",
    "\n",
    "def _collect_by_canonical(p1_tr: List[Dict[str, Any]],\n",
    "                          p2_tr: List[Dict[str, Any]],\n",
    "                          p3_tr: List[Dict[str, Any]]) -> Dict[Tuple[str,str,str], List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Build a map: canonical (s,p,o) -> list of triple instances across prompts.\n",
    "    \"\"\"\n",
    "    by_key: Dict[Tuple[str,str,str], List[Dict[str, Any]]] = {}\n",
    "    for t in (p1_tr + p2_tr + p3_tr):\n",
    "        k = t.get(\"canonical\")\n",
    "        if not k:\n",
    "            k = canonical_triple_key(t.get(\"s\"), t.get(\"p\"), t.get(\"o\"))\n",
    "            t[\"canonical\"] = k\n",
    "        by_key.setdefault(k, []).append(t)\n",
    "    return by_key\n",
    "\n",
    "def _rule_a_select(by_key: Dict[Tuple[str,str,str], List[Dict[str, Any]]],\n",
    "                   input_text: str,\n",
    "                   threshold: float = 0.90,\n",
    "                   debug: bool = False) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Rule A: Consensus selection.\n",
    "    - Same canonical triple appears in >= 2 distinct prompts.\n",
    "    - Subject and Object both fuzzy-match the full input text (>= threshold).\n",
    "    Returns representative triple dicts (original s,p,o preserved).\n",
    "    \"\"\"\n",
    "    selected: List[Dict[str, Any]] = []\n",
    "    for k, insts in by_key.items():\n",
    "        prompts = {t.get(\"source_prompt\") for t in insts}\n",
    "        if len(prompts) >= 2:\n",
    "            rep = _choose_surface_variant(insts)\n",
    "            s, o = rep[\"s\"], rep[\"o\"]\n",
    "            s_ok, s_score = fuzzy_in(s, input_text, threshold)\n",
    "            o_ok, o_score = fuzzy_in(o, input_text, threshold)\n",
    "\n",
    "            if s_ok and o_ok:\n",
    "                selected.append(rep)\n",
    "                if debug:\n",
    "                    print(f\"  [Rule A PASS] {rep['s']} — {rep['p']} — {rep['o']}  (s={s_score:.2f}, o={o_score:.2f}) from {sorted(prompts)}\")\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"  [Rule A FAIL] {rep['s']} — {rep['p']} — {rep['o']}  \"\n",
    "                          f\"(s={s_score:.2f}, o={o_score:.2f}) from {sorted(prompts)}\")\n",
    "    return selected\n",
    "\n",
    "def _present_in_support_and_input(s: str, support: str, input_text: str, thr: float) -> Tuple[bool, float, float]:\n",
    "    \"\"\"Utility: check s appears in BOTH support and input_text.\"\"\"\n",
    "    in_sup, sup_sc = fuzzy_in(s, support, thr)\n",
    "    in_inp, inp_sc = fuzzy_in(s, input_text, thr)\n",
    "    return (in_sup and in_inp, sup_sc, inp_sc)\n",
    "\n",
    "def _rule_b_select(by_key: Dict[Tuple[str,str,str], List[Dict[str, Any]]],\n",
    "                   input_text: str,\n",
    "                   threshold: float = 0.90,\n",
    "                   evidence_cut: float = 0.70,\n",
    "                   debug: bool = False) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Rule B: Single-prompt with evidence.\n",
    "    - Only in 1 prompt; support required.\n",
    "    - COLOC: subj & obj & rel all in support (>=thr) AND each in input (>=thr) → 1.0 else 0.0\n",
    "    - SUBJ_SUP: subject in support (>=thr) AND object NOT in support AND relation NOT in support → 1.0 else 0.0\n",
    "    - OBJ_SUP: object in support (>=thr) AND subject NOT in support AND relation NOT in support → 1.0 else 0.0\n",
    "    - SIM: Jaccard(support_concat, input_text) in [0,1]\n",
    "    - Evidence = 0.50*COLOC + 0.25*SUBJ_SUP + 0.25*OBJ_SUP + 0.10*SIM; keep if > evidence_cut\n",
    "    \"\"\"\n",
    "    selected: List[Dict[str, Any]] = []\n",
    "\n",
    "    for k, insts in by_key.items():\n",
    "        prompts = {t.get(\"source_prompt\") for t in insts}\n",
    "        if len(prompts) != 1:\n",
    "            continue  # not a single-prompt case\n",
    "\n",
    "        t = insts[0]\n",
    "        s, p, o = t[\"s\"], t[\"p\"], t[\"o\"]\n",
    "        sup = t.get(\"support_text\")\n",
    "        if not sup:\n",
    "            if debug:\n",
    "                print(f\"  [Rule B REJECT] (no support) {s} — {p} — {o}\")\n",
    "            continue  # support required → reject\n",
    "\n",
    "        # COLOC: subj+obj+rel in support & in input\n",
    "        s_co, s_sup_sc, s_inp_sc = _present_in_support_and_input(s, sup, input_text, threshold)\n",
    "        o_co, o_sup_sc, o_inp_sc = _present_in_support_and_input(o, sup, input_text, threshold)\n",
    "        p_co, p_sup_sc, p_inp_sc = _present_in_support_and_input(p, sup, input_text, threshold)\n",
    "        coloc = 1.0 if (s_co and o_co and p_co) else 0.0\n",
    "\n",
    "        # SUBJ_SUP: subject in support AND object NOT in support AND relation NOT in support\n",
    "        subj_in_sup, _ = fuzzy_in(s, sup, threshold)\n",
    "        obj_in_sup, _ = fuzzy_in(o, sup, threshold)\n",
    "        rel_in_sup, _ = fuzzy_in(p, sup, threshold)\n",
    "        subj_sup = 1.0 if (subj_in_sup and not obj_in_sup and not rel_in_sup) else 0.0\n",
    "\n",
    "        # OBJ_SUP: object in support AND subject NOT in support AND relation NOT in support\n",
    "        obj_sup = 1.0 if (obj_in_sup and not subj_in_sup and not rel_in_sup) else 0.0\n",
    "\n",
    "        # SIM: Jaccard(support, input_text)\n",
    "        sim = jaccard_similarity(sup, input_text)\n",
    "        if sim < 0.0:  # defensive (shouldn't happen)\n",
    "            sim = 0.0\n",
    "        if sim > 1.0:\n",
    "            sim = 1.0\n",
    "\n",
    "        evidence = (0.50 * coloc) + (0.25 * subj_sup) + (0.25 * obj_sup) + (0.10 * sim)\n",
    "        evidence = max(0.0, min(1.0, evidence))\n",
    "\n",
    "        if evidence > evidence_cut:\n",
    "            selected.append(t)\n",
    "            if debug:\n",
    "                print(f\"  [Rule B PASS] {s} — {p} — {o} | \"\n",
    "                      f\"COLOC={coloc:.2f} (s_sup={s_sup_sc:.2f}, o_sup={o_sup_sc:.2f}, p_sup={p_sup_sc:.2f}; \"\n",
    "                      f\"s_inp={s_inp_sc:.2f}, o_inp={o_inp_sc:.2f}, p_inp={p_inp_sc:.2f}) \"\n",
    "                      f\"| SUBJ_SUP={subj_sup:.2f} | OBJ_SUP={obj_sup:.2f} | SIM={sim:.2f} \"\n",
    "                      f\"| Evidence={evidence:.2f}\")\n",
    "        else:\n",
    "            if debug:\n",
    "                print(f\"  [Rule B FAIL] {s} — {p} — {o} | \"\n",
    "                      f\"COLOC={coloc:.2f} (s_sup={s_sup_sc:.2f}, o_sup={o_sup_sc:.2f}, p_sup={p_sup_sc:.2f}; \"\n",
    "                      f\"s_inp={s_inp_sc:.2f}, o_inp={o_inp_sc:.2f}, p_inp={p_inp_sc:.2f}) \"\n",
    "                      f\"| SUBJ_SUP={subj_sup:.2f} | OBJ_SUP={obj_sup:.2f} | SIM={sim:.2f} \"\n",
    "                      f\"| Evidence={evidence:.2f}\")\n",
    "\n",
    "    return selected\n",
    "\n",
    "# ---------- Public API: Evaluate & Write ----------\n",
    "\n",
    "def evaluate_ids(index_by_id: Dict[str, Dict[str, Any]],\n",
    "                 out_jsonl_path: str,\n",
    "                 limit_ids: Optional[int] = None,\n",
    "                 debug: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Run evaluator over the cross-prompt index and write final filtered triples to JSONL.\n",
    "    - limit_ids: if provided, only process the first N IDs (sorted numerically by trailing digits).\n",
    "    - debug: print per-ID details (Rule A/B decisions and evidence).\n",
    "    Output JSONL per line:\n",
    "      {\"id\":\"...\",\"input_text\":\"...\",\"triples\":[{\"s\":\"...\",\"p\":\"...\",\"o\":\"...\"}]}\n",
    "      If no triple selected for an ID → \"triples\": null\n",
    "    \"\"\"\n",
    "    # Sort IDs numerically by any trailing digits for stable, human-friendly processing\n",
    "    def sort_key(x):\n",
    "        m = re.findall(r\"(\\d+)$\", x)\n",
    "        return int(m[0]) if m else x\n",
    "    all_ids = sorted(index_by_id.keys(), key=sort_key)\n",
    "\n",
    "    if limit_ids is not None:\n",
    "        ids = all_ids[:limit_ids]\n",
    "    else:\n",
    "        ids = all_ids\n",
    "\n",
    "    # Open output file\n",
    "    with open(out_jsonl_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for rid in ids:\n",
    "            rec = index_by_id[rid]\n",
    "            input_text = rec.get(\"input_text\") or \"\"\n",
    "\n",
    "            # triples by prompt\n",
    "            p1_tr = rec.get(\"p1\", [])\n",
    "            p2_tr = rec.get(\"p2\", [])\n",
    "            p3_tr = rec.get(\"p3\", [])\n",
    "\n",
    "            # Build consensus map\n",
    "            by_key = _collect_by_canonical(p1_tr, p2_tr, p3_tr)\n",
    "\n",
    "            if debug:\n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(f\"[ID] {rid}\")\n",
    "                print(f\"  P1 triples: {len(p1_tr)} | P2: {len(p2_tr)} | P3: {len(p3_tr)}\")\n",
    "                print(\"  → Running Rule A (consensus ≥ 2 prompts) …\")\n",
    "\n",
    "            # Rule A selection\n",
    "            sel_a = _rule_a_select(by_key, input_text, threshold=0.90, debug=debug)\n",
    "\n",
    "            # Rule B selection\n",
    "            if debug:\n",
    "                print(\"  → Running Rule B (single-prompt with evidence) …\")\n",
    "            sel_b = _rule_b_select(by_key, input_text, threshold=0.90, evidence_cut=0.70, debug=debug)\n",
    "\n",
    "            # Merge and dedup final selections by canonical; pick the best surface variant\n",
    "            final_map: Dict[Tuple[str,str,str], List[Dict[str, Any]]] = {}\n",
    "            for t in (sel_a + sel_b):\n",
    "                k = t.get(\"canonical\")\n",
    "                final_map.setdefault(k, []).append(t)\n",
    "\n",
    "            final_triples: List[Dict[str, str]] = []\n",
    "            for k, insts in final_map.items():\n",
    "                rep = _choose_surface_variant(insts)\n",
    "                final_triples.append({\"s\": rep[\"s\"], \"p\": rep[\"p\"], \"o\": rep[\"o\"]})\n",
    "\n",
    "            if debug:\n",
    "                print(f\"  → Selected triples: {len(final_triples)}\")\n",
    "                for tt in final_triples:\n",
    "                    print(f\"    [SELECTED] {tt['s']} — {tt['p']} — {tt['o']}\")\n",
    "\n",
    "            # Write record\n",
    "            out_obj = {\n",
    "                \"id\": rid,\n",
    "                \"input_text\": input_text,\n",
    "                \"triples\": final_triples if final_triples else None\n",
    "            }\n",
    "            fout.write(json.dumps(out_obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n[Evaluator] Done.\")\n",
    "        print(f\"Wrote results to: {out_jsonl_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4f6e4cf-a04d-4dc8-8add-87685e907c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[ID] ont_12_monument_test_1\n",
      "  P1 triples: 0 | P2: 3 | P3: 3\n",
      "  → Running Rule A (consensus ≥ 2 prompts) …\n",
      "  [Rule A PASS] The 14th New Jersey Volunteer Infantry Monument — location — Monocacy National Battlefield  (s=1.00, o=1.00) from ['P2', 'P3']\n",
      "  → Running Rule B (single-prompt with evidence) …\n",
      "  [Rule B FAIL] The 14th New Jersey Volunteer Infantry Monument — country — US | COLOC=0.00 (s_sup=0.25, o_sup=1.00, p_sup=0.53; s_inp=1.00, o_inp=1.00, p_inp=0.62) | SUBJ_SUP=0.00 | OBJ_SUP=1.00 | SIM=0.29 | Evidence=0.28\n",
      "  [Rule B FAIL] Monocacy National Battlefield — district — US | COLOC=0.00 (s_sup=1.00, o_sup=0.00, p_sup=0.29; s_inp=1.00, o_inp=1.00, p_inp=1.00) | SUBJ_SUP=1.00 | OBJ_SUP=0.00 | SIM=0.18 | Evidence=0.27\n",
      "  [Rule B FAIL] The 14th New Jersey Volunteer Infantry Monument — established — 11 July 1907 | COLOC=0.00 (s_sup=0.17, o_sup=1.00, p_sup=1.00; s_inp=1.00, o_inp=1.00, p_inp=1.00) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.25 | Evidence=0.03\n",
      "  [Rule B FAIL] The 14th New Jersey Volunteer Infantry Monument — district — US | COLOC=0.00 (s_sup=0.25, o_sup=1.00, p_sup=1.00; s_inp=1.00, o_inp=1.00, p_inp=1.00) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.32 | Evidence=0.03\n",
      "  → Selected triples: 1\n",
      "    [SELECTED] The 14th New Jersey Volunteer Infantry Monument — location — Monocacy National Battlefield\n",
      "\n",
      "================================================================================\n",
      "[ID] ont_12_monument_test_2\n",
      "  P1 triples: 0 | P2: 5 | P3: 4\n",
      "  → Running Rule A (consensus ≥ 2 prompts) …\n",
      "  [Rule A PASS] Monocacy National Battlefield — nearestCity — Frederick, Maryland  (s=1.00, o=1.00) from ['P2', 'P3']\n",
      "  → Running Rule B (single-prompt with evidence) …\n",
      "  [Rule B FAIL] Monocacy National Battlefield — location — Frederick, Maryland | COLOC=0.00 (s_sup=0.45, o_sup=0.32, p_sup=1.00; s_inp=1.00, o_inp=1.00, p_inp=1.00) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.42 | Evidence=0.04\n",
      "  [Rule B FAIL] Frederick, Maryland — capital — null | COLOC=0.00 (s_sup=0.09, o_sup=1.00, p_sup=0.18; s_inp=1.00, o_inp=0.33, p_inp=0.55) | SUBJ_SUP=0.00 | OBJ_SUP=1.00 | SIM=0.00 | Evidence=0.25\n",
      "  [Rule B FAIL] null — country — US | COLOC=0.00 (s_sup=0.33, o_sup=1.00, p_sup=0.31; s_inp=0.33, o_inp=1.00, p_inp=0.62) | SUBJ_SUP=0.00 | OBJ_SUP=1.00 | SIM=0.12 | Evidence=0.26\n",
      "  [Rule B FAIL] null — district — US | COLOC=0.00 (s_sup=0.33, o_sup=1.00, p_sup=1.00; s_inp=0.33, o_inp=1.00, p_inp=1.00) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.31 | Evidence=0.03\n",
      "  [Rule B FAIL] Monocacy National Battlefield — location — Place | COLOC=0.00 (s_sup=1.00, o_sup=0.31, p_sup=0.62; s_inp=1.00, o_inp=0.33, p_inp=1.00) | SUBJ_SUP=1.00 | OBJ_SUP=0.00 | SIM=0.12 | Evidence=0.26\n",
      "  [Rule B FAIL] 14th New Jersey Volunteer Infantry Monument — location — Place | COLOC=0.00 (s_sup=0.14, o_sup=0.31, p_sup=0.62; s_inp=1.00, o_inp=0.33, p_inp=1.00) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.12 | Evidence=0.01\n",
      "  [Rule B FAIL] Monocacy National Battlefield — district — Place | COLOC=0.00 (s_sup=0.31, o_sup=0.33, p_sup=1.00; s_inp=1.00, o_inp=0.33, p_inp=1.00) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.31 | Evidence=0.03\n",
      "  → Selected triples: 1\n",
      "    [SELECTED] Monocacy National Battlefield — nearestCity — Frederick, Maryland\n",
      "\n",
      "================================================================================\n",
      "[ID] ont_12_monument_test_3\n",
      "  P1 triples: 0 | P2: 3 | P3: 4\n",
      "  → Running Rule A (consensus ≥ 2 prompts) …\n",
      "  [Rule A PASS] The 14th New Jersey Volunteer Infantry Monument — established — July 11th, 1907  (s=1.00, o=1.00) from ['P2', 'P3']\n",
      "  → Running Rule B (single-prompt with evidence) …\n",
      "  [Rule B FAIL] The 14th New Jersey Volunteer Infantry Monument — location — historic district | COLOC=0.00 (s_sup=1.00, o_sup=1.00, p_sup=0.33; s_inp=1.00, o_inp=1.00, p_inp=0.62) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.68 | Evidence=0.07\n",
      "  [Rule B FAIL] The United States — district — historic district | COLOC=0.00 (s_sup=0.44, o_sup=0.28, p_sup=0.53; s_inp=0.56, o_inp=1.00, p_inp=1.00) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.27 | Evidence=0.03\n",
      "  [Rule B FAIL] The 14th New Jersey Volunteer Infantry Monument — location — a historic district | COLOC=0.00 (s_sup=0.12, o_sup=1.00, p_sup=0.33; s_inp=1.00, o_inp=1.00, p_inp=0.62) | SUBJ_SUP=0.00 | OBJ_SUP=1.00 | SIM=0.14 | Evidence=0.26\n",
      "  [Rule B FAIL] The 14th New Jersey Volunteer Infantry Monument — district — US | COLOC=0.00 (s_sup=0.24, o_sup=0.22, p_sup=0.53; s_inp=1.00, o_inp=1.00, p_inp=1.00) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.27 | Evidence=0.03\n",
      "  [Rule B REJECT] (no support) US — capital — not mentioned\n",
      "  → Selected triples: 1\n",
      "    [SELECTED] The 14th New Jersey Volunteer Infantry Monument — established — July 11th, 1907\n",
      "\n",
      "================================================================================\n",
      "[ID] ont_12_monument_test_4\n",
      "  P1 triples: 0 | P2: 3 | P3: 2\n",
      "  → Running Rule A (consensus ≥ 2 prompts) …\n",
      "  [Rule A PASS] The 14th New Jersey Volunteer Infantry Monument — location — Historic districts  (s=1.00, o=1.00) from ['P2', 'P3']\n",
      "  → Running Rule B (single-prompt with evidence) …\n",
      "  [Rule B FAIL] The 14th New Jersey Volunteer Infantry Monument — location — United States | COLOC=0.00 (s_sup=1.00, o_sup=1.00, p_sup=0.50; s_inp=1.00, o_inp=1.00, p_inp=0.50) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=1.00 | Evidence=0.10\n",
      "  [Rule B FAIL] The 14th New Jersey Volunteer Infantry Monument — established — 11th July 1907 | COLOC=1.00 (s_sup=1.00, o_sup=1.00, p_sup=1.00; s_inp=1.00, o_inp=1.00, p_inp=1.00) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=1.00 | Evidence=0.60\n",
      "  [Rule B FAIL] The 14th New Jersey Volunteer Infantry Monument — location — 11th July 1907 | COLOC=0.00 (s_sup=0.29, o_sup=1.00, p_sup=0.40; s_inp=1.00, o_inp=1.00, p_inp=0.50) | SUBJ_SUP=0.00 | OBJ_SUP=1.00 | SIM=0.22 | Evidence=0.27\n",
      "  → Selected triples: 1\n",
      "    [SELECTED] The 14th New Jersey Volunteer Infantry Monument — location — Historic districts\n",
      "\n",
      "================================================================================\n",
      "[ID] ont_12_monument_test_5\n",
      "  P1 triples: 0 | P2: 3 | P3: 3\n",
      "  → Running Rule A (consensus ≥ 2 prompts) …\n",
      "  → Running Rule B (single-prompt with evidence) …\n",
      "  [Rule B FAIL] Monocacy National Battlefield — location — Frederick Maryland | COLOC=0.00 (s_sup=0.38, o_sup=0.33, p_sup=0.67; s_inp=1.00, o_inp=1.00, p_inp=0.67) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.40 | Evidence=0.04\n",
      "  [Rule B FAIL] Frederick Maryland — nearestCity — Monocacy National Battlefield | COLOC=0.00 (s_sup=0.27, o_sup=1.00, p_sup=0.96; s_inp=1.00, o_inp=1.00, p_inp=0.96) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.24 | Evidence=0.02\n",
      "  [Rule B FAIL] Monocacy National Battlefield — established — 11 July 1907 | COLOC=0.00 (s_sup=0.26, o_sup=1.00, p_sup=1.00; s_inp=1.00, o_inp=1.00, p_inp=1.00) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.28 | Evidence=0.03\n",
      "  [Rule B FAIL] Monocacy National Battlefield — nearestCity — Frederick Maryland | COLOC=1.00 (s_sup=1.00, o_sup=1.00, p_sup=0.96; s_inp=1.00, o_inp=1.00, p_inp=0.96) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.40 | Evidence=0.54\n",
      "  [Rule B FAIL] 14th New Jersey Volunteer infantry monument — location — Monocacy National Battlefield | COLOC=0.00 (s_sup=1.00, o_sup=1.00, p_sup=0.67; s_inp=1.00, o_inp=1.00, p_inp=0.67) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.46 | Evidence=0.05\n",
      "  [Rule B FAIL] 14th New Jersey Volunteer infantry monument — established — 11 July 1907 | COLOC=0.00 (s_sup=0.17, o_sup=1.00, p_sup=1.00; s_inp=1.00, o_inp=1.00, p_inp=1.00) | SUBJ_SUP=0.00 | OBJ_SUP=0.00 | SIM=0.28 | Evidence=0.03\n",
      "  → Selected triples: 0\n",
      "\n",
      "[Evaluator] Done.\n",
      "Wrote results to: evaluator_output_debug.jsonl\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ... after building INDEX_BY_ID in Block 2 ...\n",
    "    evaluate_ids(INDEX_BY_ID, out_jsonl_path=\"evaluator_output_debug.jsonl\", limit_ids=5, debug=True)\n",
    "    # When satisfied, run on all:\n",
    "    # evaluate_ids(INDEX_BY_ID, out_jsonl_path=\"evaluator_output_all.jsonl\", limit_ids=None, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfdbcfad-87fc-49bf-83bf-4c7f516e091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # After Block 2 produced INDEX_BY_ID\n",
    "    evaluate_ids(\n",
    "        INDEX_BY_ID,\n",
    "        out_jsonl_path=\"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/final_triples/dbpedia/ont_12_monument_final_output_latest.jsonl\",\n",
    "        limit_ids=None,     # process all IDs\n",
    "        debug=False          # turn off debug printing\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb0d8c5-d5df-466a-9bda-3b7ba564b4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_pipeline",
   "language": "python",
   "name": "kg_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
