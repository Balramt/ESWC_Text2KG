{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a562f097-b19d-4c65-be00-bd9a53ec5ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 30 18:54:13 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:81:00.0 Off |                  N/A |\n",
      "| 67%   61C    P0            281W /  370W |   14418MiB /  24576MiB |     52%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   1150845      C   ....conda/envs/kg_pipeline/bin/python3      14408MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe4feed-deef-46e9-8a29-5fa4a1f70e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 1106593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba3e522e-b082-418d-85f8-dc6e51b04a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limbo\n",
      "/opt/miniforge3/envs/jupyterhub/bin/python\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "!hostname\n",
    "!which python\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28bc8447-99bb-4400-a759-80c6f9cfb589",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# BLOCK 1: IMPORTS / GLOBAL CONFIG / MODEL SETUP\n",
    "########################################\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from textwrap import dedent\n",
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "\n",
    "# -------- Runtime config (edit these before running Block 13 manual test) --------\n",
    "ONTOLOGY_JSON = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/1_movie_ontology.json\"\n",
    "INPUT_JSONL   = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_text/ont_1_movie_test.jsonl\"\n",
    "OUTPUT_JSONL  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt2/wikidata/ont_1_movie_output_test.jsonl\"\n",
    "\n",
    "MODEL_ID   = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "K_TRIPLES  = 1        # \"extract up to {k} triples\"\n",
    "MAX_ITEMS  = 16     # None = use all rows from INPUT_JSONL\n",
    "VERBOSE    = True     # default True for manual testing first\n",
    "\n",
    "\n",
    "def setup_model(model_id: str = \"mistralai/Mistral-7B-Instruct-v0.3\"):\n",
    "    \"\"\"\n",
    "    Load the chat model + tokenizer and return a text-generation pipeline.\n",
    "    Uses half precision + device_map='auto' for efficiency.\n",
    "    \"\"\"\n",
    "    print(f\"[LOAD] model={model_id}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "    model.config.use_cache = True\n",
    "\n",
    "    generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    return generator, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d85a8a0-3c6a-4586-b569-565d19580104",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# BLOCK 2: DATA I/O HELPERS\n",
    "########################################\n",
    "\n",
    "_TEXT_KEYS_PRIORITY = (\"sent\", \"text\", \"Text\", \"sentence\", \"Sentence\")\n",
    "\n",
    "\n",
    "def read_jsonl(path: str, max_items: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Stream records from a .jsonl file.\n",
    "    Stops early if max_items is provided.\n",
    "    Yields dicts.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            yield json.loads(line)\n",
    "            count += 1\n",
    "            if max_items is not None and count >= max_items:\n",
    "                break\n",
    "\n",
    "\n",
    "def write_jsonl(path: str, records: List[Dict[str, Any]]):\n",
    "    \"\"\"\n",
    "    Write a list of dicts as JSON lines.\n",
    "    Creates parent directory if needed.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for rec in records:\n",
    "            f.write(json.dumps(rec, ensure_ascii=False))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "\n",
    "def extract_text_field(rec: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Heuristic to pick the text field from an input record.\n",
    "    Returns (text_value, key_used).\n",
    "    Falls back to the longest string field if none of the preferred keys exist.\n",
    "    \"\"\"\n",
    "    for k in _TEXT_KEYS_PRIORITY:\n",
    "        v = rec.get(k)\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            return v.strip(), k\n",
    "\n",
    "    # fallback: choose longest string in record\n",
    "    best_key, best_val = \"\", \"\"\n",
    "    for k, v in rec.items():\n",
    "        if isinstance(v, str) and len(v) > len(best_val):\n",
    "            best_key, best_val = k, v\n",
    "    return best_val.strip(), best_key\n",
    "\n",
    "\n",
    "def _escape_multiline(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Escape backslashes and quotes so we can safely embed text\n",
    "    inside quoted blocks in the USER prompt.\n",
    "    \"\"\"\n",
    "    return s.replace(\"\\\\\", \"\\\\\\\\\").replace('\"', '\\\\\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87a61603-701b-417a-993e-aa98038fe4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# BLOCK 3: ONTOLOGY HELPERS + PROMPT 2 MESSAGE BUILDERS\n",
    "########################################\n",
    "\n",
    "def load_ontology_json(path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load ontology JSON file.\n",
    "    Expected structure:\n",
    "      {\n",
    "        \"concepts\": [\n",
    "          {\"id\": \"...\", \"qid\": \"...\", \"label\": \"SomeClass\"},\n",
    "          ...\n",
    "        ],\n",
    "        \"relations\": [\n",
    "          {\n",
    "            \"id\": \"...\",\n",
    "            \"label\": \"location\",\n",
    "            \"domain\": \"SomeConceptID\",\n",
    "            \"range\": \"SomeConceptID\"\n",
    "          },\n",
    "          ...\n",
    "        ]\n",
    "      }\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def _build_concept_index(ontology_json: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Map any known identifier (qid/id/label) -> canonical label string.\n",
    "    This lets us convert domain/range IDs into human-readable names.\n",
    "    \"\"\"\n",
    "    idx: Dict[str, str] = {}\n",
    "    for concept in ontology_json.get(\"concepts\", []):\n",
    "        label = str(concept.get(\"label\", \"\")).strip()\n",
    "        if not label:\n",
    "            continue\n",
    "\n",
    "        for keyname in (\"qid\", \"id\", \"label\"):\n",
    "            raw_val = concept.get(keyname)\n",
    "            if raw_val is None:\n",
    "                continue\n",
    "\n",
    "            sval = str(raw_val).strip()\n",
    "            if sval:\n",
    "                idx[sval] = label\n",
    "    return idx\n",
    "\n",
    "\n",
    "def _label_for(raw_val: Any, cindex: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Convert domain/range IDs to readable labels.\n",
    "    Fallback to string form of raw_val.\n",
    "    \"\"\"\n",
    "    if raw_val is None:\n",
    "        return \"\"\n",
    "    rval = str(raw_val).strip()\n",
    "    return cindex.get(rval, rval)\n",
    "\n",
    "\n",
    "def format_ontology_concepts(ontology_json: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Return a bullet list of ontology concepts by label.\n",
    "    We'll present these to the model.\n",
    "    \"\"\"\n",
    "    lines: List[str] = []\n",
    "    for c in ontology_json.get(\"concepts\", []):\n",
    "        label = str(c.get(\"label\", \"\")).strip()\n",
    "        if label:\n",
    "            lines.append(f\"- {label}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def format_ontology_relations(ontology_json: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Return a bullet list of relations with (domain, range) in human-readable form.\n",
    "    Format: - relationLabel(domainLabel,rangeLabel)\n",
    "    \"\"\"\n",
    "    cindex = _build_concept_index(ontology_json)\n",
    "    lines: List[str] = []\n",
    "    for r in ontology_json.get(\"relations\", []):\n",
    "        rel_label = str(r.get(\"label\", \"\")).strip()\n",
    "        dom_label = _label_for(r.get(\"domain\"), cindex)\n",
    "        rng_label = _label_for(r.get(\"range\"), cindex)\n",
    "        if rel_label:\n",
    "            lines.append(f\"- {rel_label}({dom_label},{rng_label})\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def build_p2_system() -> str:\n",
    "    \"\"\"\n",
    "    System message for Prompt 2.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"You are a KG triple extractor. \"\n",
    "        \"Match relation cues in the text and return only triples that satisfy the \"\n",
    "        \"ontology’s domain→range. Cite exact evidence. Output JSON only.\"\n",
    "    )\n",
    "\n",
    "def build_p2_user(text: str, ontology_json: Dict[str, Any], k: int) -> str:\n",
    "    \"\"\"\n",
    "    Prompt 2 user message:\n",
    "    - No few-shot examples\n",
    "    - No per-domain lists\n",
    "    - Includes a universal explanation of how to recognize and record lexical cues\n",
    "    \"\"\"\n",
    "\n",
    "    ontology_concepts_block = format_ontology_concepts(ontology_json)\n",
    "    ontology_relations_block = format_ontology_relations(ontology_json)\n",
    "\n",
    "    return dedent(f\"\"\"\\\n",
    "    Task: Using explicit lexical cues found in the text, extract up to {k} triples [subject, relation, object].\n",
    "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
    "\n",
    "    CUE GENERATION GUIDANCE:\n",
    "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
    "      and signals the relation between them.\n",
    "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
    "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
    "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
    "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
    "    - The cue expresses the natural-language realization of the ontology relation.\n",
    "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
    "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
    "\n",
    "    PROCEDURE:\n",
    "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
    "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
    "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
    "    4. If none is found, do not emit a triple for that relation.\n",
    "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
    "\n",
    "    Text:\n",
    "    \"{_escape_multiline(text)}\"\n",
    "\n",
    "    Ontology concepts:\n",
    "    {ontology_concepts_block}\n",
    "\n",
    "    Ontology relations (domain → range):\n",
    "    {ontology_relations_block}\n",
    "\n",
    "    Output JSON only in this exact schema:\n",
    "    {{\n",
    "      \"triples\": [\n",
    "        {{\n",
    "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
    "          \"confidence\": 0.0,  // confidence 0–1\n",
    "          \"cue\": \"matched cue phrase from text\",\n",
    "          \"support\": \"exact quoted span(s)\",\n",
    "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "\n",
    "    Rules:\n",
    "    - Work only from visible text evidence.\n",
    "    - If no relation cue appears, return an empty list of triples.\n",
    "    - Do NOT invent or assume facts not in text.\n",
    "    - Always quote exact spans for support and cue.\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e294b47f-a711-4e30-b2f3-e2ca6ba00975",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# BLOCK 4: GENERATION + PARSER HELPERS\n",
    "########################################\n",
    "\n",
    "def generate_raw_json(\n",
    "    generator,\n",
    "    tokenizer,\n",
    "    system_prompt: str,\n",
    "    user_prompt: str,\n",
    "    max_new_tokens: int = 768,\n",
    "    temperature: float = 0.25,\n",
    "    top_p: float = 0.9,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build chat-style prompt for Prompt 2 and get model output.\n",
    "    We expect JSON-only, but we'll still post-parse later.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\",   \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    prompt_text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    out = generator(\n",
    "        prompt_text,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        do_sample=True,\n",
    "        return_full_text=False,\n",
    "        truncation=False,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    # HF pipeline returns list[{\"generated_text\": \"...\"}]\n",
    "    if isinstance(out[0], dict) and \"generated_text\" in out[0]:\n",
    "        return out[0][\"generated_text\"].strip()\n",
    "    else:\n",
    "        # fallback\n",
    "        return str(out[0]).strip()\n",
    "\n",
    "\n",
    "def try_parse_json(raw: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Best-effort parse of model output (should be JSON).\n",
    "    1. direct json.loads\n",
    "    2. fallback: grab first {...} block\n",
    "    \"\"\"\n",
    "    raw_strip = raw.strip()\n",
    "\n",
    "    # direct attempt\n",
    "    try:\n",
    "        return json.loads(raw_strip)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # fallback: regex for first {...}\n",
    "    m = re.search(r\"\\{.*\\}\", raw_strip, flags=re.DOTALL)\n",
    "    if m:\n",
    "        block = m.group(0)\n",
    "        try:\n",
    "            return json.loads(block)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "632b2df6-b110-45c6-abc2-ebf4133c37a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# BLOCK 5: SINGLE-FILE PIPELINE (Prompt 2)\n",
    "########################################\n",
    "\n",
    "\n",
    "def run_pipeline_prompt2(\n",
    "    ontology_path: str,\n",
    "    input_jsonl_path: str,\n",
    "    output_jsonl_path: str,\n",
    "    k_triples: int = 5,\n",
    "    max_items: Optional[int] = None,\n",
    "    verbose: bool = True,\n",
    "    model_id: str = \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    generator=None,\n",
    "    tokenizer=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run Prompt 2 over a single dataset file:\n",
    "      - load ontology + rows\n",
    "      - build prompts\n",
    "      - generate model output\n",
    "      - parse JSON\n",
    "      - write trace jsonl\n",
    "\n",
    "    Behavior:\n",
    "      • If `generator` and `tokenizer` are provided, reuse them (no new model load).\n",
    "      • Otherwise, load the model from `model_id` internally (backward compatible).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. load ontology\n",
    "    ontology_json = load_ontology_json(ontology_path)\n",
    "\n",
    "    # 2. init / reuse model\n",
    "    local_model_loaded = False\n",
    "    if generator is None or tokenizer is None:\n",
    "        generator, tokenizer = setup_model(model_id=model_id)\n",
    "        local_model_loaded = True  # so we know we \"own\" it, if you ever want cleanup\n",
    "\n",
    "    results: List[Dict[str, Any]] = []\n",
    "\n",
    "    # 3. iterate input rows\n",
    "    for idx, rec in enumerate(read_jsonl(input_jsonl_path, max_items=max_items)):\n",
    "        rec_id = str(rec.get(\"id\") or f\"item_{idx}\")\n",
    "        text_val, text_key = extract_text_field(rec)\n",
    "\n",
    "        sys_prompt = build_p2_system()\n",
    "        usr_prompt = build_p2_user(text_val, ontology_json, k_triples)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"======================================\")\n",
    "            print(f\"[ID] {rec_id}\")\n",
    "            print(f\"[TEXT_KEY] {text_key}\")\n",
    "            print(\"[SYSTEM PROMPT]\\n\", sys_prompt)\n",
    "            print(\"[USER PROMPT]\\n\", usr_prompt)\n",
    "            print(\"[SOURCE TEXT]\\n\", text_val)\n",
    "\n",
    "        raw_response = generate_raw_json(\n",
    "            generator=generator,\n",
    "            tokenizer=tokenizer,\n",
    "            system_prompt=sys_prompt,\n",
    "            user_prompt=usr_prompt,\n",
    "            max_new_tokens=768,\n",
    "            temperature=0.25,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "\n",
    "        parsed_json = try_parse_json(raw_response)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"[RAW RESPONSE]\\n\", raw_response)\n",
    "            print(\"[PARSED JSON]\\n\", parsed_json)\n",
    "\n",
    "        out_record = {\n",
    "            \"id\": rec_id,\n",
    "            \"input text\": text_val,\n",
    "            \"prompts\": {\n",
    "                \"system_prompt\": sys_prompt,\n",
    "                \"user_prompt\": usr_prompt,\n",
    "            },\n",
    "            \"response\": {\n",
    "                \"LLM_output\": raw_response,\n",
    "                \"json\": parsed_json,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        results.append(out_record)\n",
    "\n",
    "    # 4. write collected results\n",
    "    write_jsonl(output_jsonl_path, results)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n[P2 WRITE] {len(results)} rows -> {output_jsonl_path}\")\n",
    "\n",
    "    # optional: if we loaded the model here locally we *could* free VRAM,\n",
    "    # but usually you keep it for interactive use.\n",
    "    # if local_model_loaded:\n",
    "    #     torch.cuda.empty_cache()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d6081-fb76-4586-98c2-d063a0a88571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ed1a7d6-2745-478f-9b6d-680b2be6e245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] model=mistralai/Mistral-7B-Instruct-v0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dd6118c80742f5875a8208cac59300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "[ID] ont_1_movie_test_1\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Bleach: Hell Verse (Japanese: BLEACH , Hepburn: BurÄ«chi Jigoku-Hen) is a 2010 Japanese animated film directed by Noriyuki Abe.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Bleach: Hell Verse (Japanese: BLEACH , Hepburn: BurÄ«chi Jigoku-Hen) is a 2010 Japanese animated film directed by Noriyuki Abe.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Bleach: Hell Verse\", \"directed by\", \"Noriyuki Abe\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"directed by\",\n",
      "      \"support\": \"Noriyuki Abe\",\n",
      "      \"notes\": \"The subject and object are both films, and the cue 'directed by' expresses the ontology relation 'director(film,human)'. No pronoun resolution was needed.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['Bleach: Hell Verse', 'directed by', 'Noriyuki Abe'], 'confidence': 1.0, 'cue': 'directed by', 'support': 'Noriyuki Abe', 'notes': \"The subject and object are both films, and the cue 'directed by' expresses the ontology relation 'director(film,human)'. No pronoun resolution was needed.\"}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_2\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Keyboard Cat's original form was a video originally made in 1984 by Charlie Schmidt of his cat Fatso seemingly playing a piano (though manipulated by Schmidt off-camera) to a cheery tune.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Keyboard Cat's original form was a video originally made in 1984 by Charlie Schmidt of his cat Fatso seemingly playing a piano (though manipulated by Schmidt off-camera) to a cheery tune.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Charlie Schmidt\", \"director\", \"Keyboard Cat's original form\"],\n",
      "      \"confidence\": 0.8,\n",
      "      \"cue\": \"made\",\n",
      "      \"support\": \"Charlie Schmidt of his cat Fatso seemingly playing a piano (though manipulated by Schmidt off-camera) to a cheery tune.\",\n",
      "      \"notes\": \"Inferred subject and object from the text. The relation 'director' is inferred as Charlie Schmidt is the one who made the video.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Keyboard Cat's original form\", \"genre\", \"not specified\"],\n",
      "      \"confidence\": 0.6,\n",
      "      \"cue\": \"to a cheery tune\",\n",
      "      \"support\": \"to a cheery tune.\",\n",
      "      \"notes\": \"Inferred subject and relation from the text. The genre of the video is not explicitly stated.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['Charlie Schmidt', 'director', \"Keyboard Cat's original form\"], 'confidence': 0.8, 'cue': 'made', 'support': 'Charlie Schmidt of his cat Fatso seemingly playing a piano (though manipulated by Schmidt off-camera) to a cheery tune.', 'notes': \"Inferred subject and object from the text. The relation 'director' is inferred as Charlie Schmidt is the one who made the video.\"}, {'triple': [\"Keyboard Cat's original form\", 'genre', 'not specified'], 'confidence': 0.6, 'cue': 'to a cheery tune', 'support': 'to a cheery tune.', 'notes': 'Inferred subject and relation from the text. The genre of the video is not explicitly stated.'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_3\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"The series was directed by Mitsuko Kase (episodes 1-7) and Takashi Imanishi (episodes 8-13).\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " The series was directed by Mitsuko Kase (episodes 1-7) and Takashi Imanishi (episodes 8-13).\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"The series\", \"directed\", \"Mitsuko Kase (episodes 1-7)\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"directed by\",\n",
      "      \"support\": \"The series was directed by Mitsuko Kase (episodes 1-7).\",\n",
      "      \"notes\": \"domain/range check: director(film,human)\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"The series\", \"directed\", \"Takashi Imanishi (episodes 8-13)\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"directed by\",\n",
      "      \"support\": \"The series was directed by Mitsuko Kase (episodes 1-7) and Takashi Imanishi (episodes 8-13).\",\n",
      "      \"notes\": \"domain/range check: director(film,human)\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['The series', 'directed', 'Mitsuko Kase (episodes 1-7)'], 'confidence': 1.0, 'cue': 'directed by', 'support': 'The series was directed by Mitsuko Kase (episodes 1-7).', 'notes': 'domain/range check: director(film,human)'}, {'triple': ['The series', 'directed', 'Takashi Imanishi (episodes 8-13)'], 'confidence': 1.0, 'cue': 'directed by', 'support': 'The series was directed by Mitsuko Kase (episodes 1-7) and Takashi Imanishi (episodes 8-13).', 'notes': 'domain/range check: director(film,human)'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_4\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Spirited Away (Japanese: , Hepburn: Sen to Chihiro no Kamikakushi, \\\"Sen and Chihiros Spiriting Away\\\") is a 2001 Japanese animated fantasy film written and directed by Hayao Miyazaki, animated by Studio Ghibli for Tokuma Shoten, Nippon Television Network, Dentsu, Buena Vista Home Entertainment, Tohokushinsha Film and Mitsubishi, and distributed by Toho.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Spirited Away (Japanese: , Hepburn: Sen to Chihiro no Kamikakushi, \"Sen and Chihiros Spiriting Away\") is a 2001 Japanese animated fantasy film written and directed by Hayao Miyazaki, animated by Studio Ghibli for Tokuma Shoten, Nippon Television Network, Dentsu, Buena Vista Home Entertainment, Tohokushinsha Film and Mitsubishi, and distributed by Toho.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Spirited Away\", \"directed by\", \"Hayao Miyazaki\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"written and directed by Hayao Miyazaki\",\n",
      "      \"support\": \"\\\"Spirited Away (Japanese:, Hepburn: Sen to Chihiro no Kamikakushi, \\\"Sen and Chihiros Spiriting Away\\\") is a 2001 Japanese animated fantasy film written and directed by Hayao Miyazaki\",\n",
      "      \"notes\": \"The subject and object are both films, and the cue 'directed by' matches the 'director(film,human)' relation.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Spirited Away\", \"animated by\", \"Studio Ghibli\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"animated by Studio Ghibli\",\n",
      "      \"support\": \"animated by Studio Ghibli\",\n",
      "      \"notes\": \"The subject and object are both films, and the cue 'animated by' matches the unspecified relation between film and film production company.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Spirited Away\", \"distributed by\", \"Toho\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"distributed by Toho\",\n",
      "      \"support\": \"distributed by Toho\",\n",
      "      \"notes\": \"The subject and object are both films, and the cue 'distributed by' matches the unspecified relation between film and film organization.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Spirited Away\", \"based on\", \"\"],\n",
      "      \"confidence\": 0.0,\n",
      "      \"cue\": \"\",\n",
      "      \"support\": \"\",\n",
      "      \"notes\": \"No cue for the 'based on(film,written work)' relation was found in the text.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"\", \"cast member\", \"Hayao Miyazaki\"],\n",
      "      \"confidence\": 0.0,\n",
      "      \"cue\": \"\",\n",
      "      \"support\": \"\",\n",
      "      \"notes\": \"No cue for the 'cast member(film,human)' relation was found in the text. The subject is not a human.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Spirited Away\", \"award received\", \"\"],\n",
      "      \"confidence\": 0.0,\n",
      "      \"cue\": \"\",\n",
      "      \"support\": \"\",\n",
      "      \"notes\": \"No cue for the 'award received(film,award)' relation was found in the text.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"\", \"production company\", \"Studio Ghibli\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"animated by Studio Ghibli\",\n",
      "      \"support\": \"animated by Studio Ghibli\",\n",
      "      \"notes\": \"The subject is not specified, but the cue 'animated by' matches the unspecified relation between film and film production company.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Spirited Away\", \"country of origin\", \"Japan\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"Japanese\",\n",
      "[PARSED JSON]\n",
      " None\n",
      "======================================\n",
      "[ID] ont_1_movie_test_5\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Looney Tunes: Back in Action is a 2003 American live-action/animated comedy film directed by Joe Dante and written by Larry Doyle.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Looney Tunes: Back in Action is a 2003 American live-action/animated comedy film directed by Joe Dante and written by Larry Doyle.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Looney Tunes: Back in Action\", \"directed by\", \"Joe Dante\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"directed by\",\n",
      "      \"support\": \"directed by Joe Dante\",\n",
      "      \"notes\": \"domain/range check: film (subject) - human (range)\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Looney Tunes: Back in Action\", \"written by\", \"Larry Doyle\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"written by\",\n",
      "      \"support\": \"written by Larry Doyle.\",\n",
      "      \"notes\": \"domain/range check: film (subject) - human (range)\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['Looney Tunes: Back in Action', 'directed by', 'Joe Dante'], 'confidence': 1.0, 'cue': 'directed by', 'support': 'directed by Joe Dante', 'notes': 'domain/range check: film (subject) - human (range)'}, {'triple': ['Looney Tunes: Back in Action', 'written by', 'Larry Doyle'], 'confidence': 1.0, 'cue': 'written by', 'support': 'written by Larry Doyle.', 'notes': 'domain/range check: film (subject) - human (range)'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_6\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"The Life on the Earth - The Summer of Dioxin ( Inochi No Chikyuu - Dioxin No Natsu), also known as Tracing the Gray Summer, is a 2001 Japanese anime drama film by Satoshi Dezaki, a joint production between the Magic Bus and the GoGo Visual Planning which recounts the true story of the Seveso disaster, a chemical incident occurred over the Italian town of Seveso in 1976, which is still considered one of the worst ecological disasters in history.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " The Life on the Earth - The Summer of Dioxin ( Inochi No Chikyuu - Dioxin No Natsu), also known as Tracing the Gray Summer, is a 2001 Japanese anime drama film by Satoshi Dezaki, a joint production between the Magic Bus and the GoGo Visual Planning which recounts the true story of the Seveso disaster, a chemical incident occurred over the Italian town of Seveso in 1976, which is still considered one of the worst ecological disasters in history.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"The Life on the Earth\", \"genre\", \"anime drama\"],\n",
      "      \"confidence\": 0.8,\n",
      "      \"cue\": \"a 2001 Japanese anime drama film\",\n",
      "      \"support\": \"The Life on the Earth - The Summer of Dioxin ( Inochi No Chikyuu - Dioxin No Natsu), also known as Tracing the Gray Summer, is a 2001 Japanese anime drama film\",\n",
      "      \"notes\": \"The exact genre is not specified, but 'anime drama' is inferred from the text.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"The Life on the Earth\", \"production company\", \"Magic Bus and the GoGo Visual Planning\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"a joint production between the Magic Bus and the GoGo Visual Planning\",\n",
      "      \"support\": \"a joint production between the Magic Bus and the GoGo Visual Planning\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"The Life on the Earth\", \"country of origin\", \"Japan\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"Japanese\",\n",
      "      \"support\": \"Japanese\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"The Life on the Earth\", \"director\", \"Satoshi Dezaki\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"by Satoshi Dezaki\",\n",
      "      \"support\": \"by Satoshi Dezaki\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['The Life on the Earth', 'genre', 'anime drama'], 'confidence': 0.8, 'cue': 'a 2001 Japanese anime drama film', 'support': 'The Life on the Earth - The Summer of Dioxin ( Inochi No Chikyuu - Dioxin No Natsu), also known as Tracing the Gray Summer, is a 2001 Japanese anime drama film', 'notes': \"The exact genre is not specified, but 'anime drama' is inferred from the text.\"}, {'triple': ['The Life on the Earth', 'production company', 'Magic Bus and the GoGo Visual Planning'], 'confidence': 1.0, 'cue': 'a joint production between the Magic Bus and the GoGo Visual Planning', 'support': 'a joint production between the Magic Bus and the GoGo Visual Planning'}, {'triple': ['The Life on the Earth', 'country of origin', 'Japan'], 'confidence': 1.0, 'cue': 'Japanese', 'support': 'Japanese'}, {'triple': ['The Life on the Earth', 'director', 'Satoshi Dezaki'], 'confidence': 1.0, 'cue': 'by Satoshi Dezaki', 'support': 'by Satoshi Dezaki'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_7\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Directed by Richard Eichberg and Walter Summers The Flame of Love stars Anna May Wong and John Longden and has a running time of 74 minutes.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Directed by Richard Eichberg and Walter Summers The Flame of Love stars Anna May Wong and John Longden and has a running time of 74 minutes.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"The Flame of Love\", \"directed by\", \"Richard Eichberg and Walter Summers\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"Directed by\",\n",
      "      \"support\": \"Directed by Richard Eichberg and Walter Summers\",\n",
      "      \"notes\": \"domain/range check: film (subject) and human (object)\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"The Flame of Love\", \"cast member\", \"Anna May Wong\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"stars\",\n",
      "      \"support\": \"stars Anna May Wong and John Longden\",\n",
      "      \"notes\": \"domain/range check: film (subject) and human (object)\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"The Flame of Love\", \"cast member\", \"John Longden\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"stars\",\n",
      "      \"support\": \"stars Anna May Wong and John Longden\",\n",
      "      \"notes\": \"domain/range check: film (subject) and human (object)\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['The Flame of Love', 'directed by', 'Richard Eichberg and Walter Summers'], 'confidence': 1.0, 'cue': 'Directed by', 'support': 'Directed by Richard Eichberg and Walter Summers', 'notes': 'domain/range check: film (subject) and human (object)'}, {'triple': ['The Flame of Love', 'cast member', 'Anna May Wong'], 'confidence': 1.0, 'cue': 'stars', 'support': 'stars Anna May Wong and John Longden', 'notes': 'domain/range check: film (subject) and human (object)'}, {'triple': ['The Flame of Love', 'cast member', 'John Longden'], 'confidence': 1.0, 'cue': 'stars', 'support': 'stars Anna May Wong and John Longden', 'notes': 'domain/range check: film (subject) and human (object)'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_8\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Metal Skin Panic MADOX-01 was directed and written by Shinji Aramaki.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Metal Skin Panic MADOX-01 was directed and written by Shinji Aramaki.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Metal Skin Panic MADOX-01\", \"directed\", \"Shinji Aramaki\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"directed and written by\",\n",
      "      \"support\": \"Metal Skin Panic MADOX-01 was directed and written by Shinji Aramaki.\",\n",
      "      \"notes\": \"domain/range check: director(film,human)\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Metal Skin Panic MADOX-01\", \"screenwriter\", \"Shinji Aramaki\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"written by\",\n",
      "      \"support\": \"Metal Skin Panic MADOX-01 was written by Shinji Aramaki.\",\n",
      "      \"notes\": \"domain/range check: screenwriter(film,human)\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['Metal Skin Panic MADOX-01', 'directed', 'Shinji Aramaki'], 'confidence': 1.0, 'cue': 'directed and written by', 'support': 'Metal Skin Panic MADOX-01 was directed and written by Shinji Aramaki.', 'notes': 'domain/range check: director(film,human)'}, {'triple': ['Metal Skin Panic MADOX-01', 'screenwriter', 'Shinji Aramaki'], 'confidence': 1.0, 'cue': 'written by', 'support': 'Metal Skin Panic MADOX-01 was written by Shinji Aramaki.', 'notes': 'domain/range check: screenwriter(film,human)'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_9\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Directed by Noriyuki Abe, the film was released December 13, 2008 in Japan, later to be released in the US.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Directed by Noriyuki Abe, the film was released December 13, 2008 in Japan, later to be released in the US.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Directed by\", \"director\", \"Noriyuki Abe\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"Directed by\",\n",
      "      \"support\": \"Directed by Noriyuki Abe\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['Directed by', 'director', 'Noriyuki Abe'], 'confidence': 1.0, 'cue': 'Directed by', 'support': 'Directed by Noriyuki Abe'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_10\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Fullmetal Alchemist the Movie: Conqueror of Shamballa (Japanese: , Hepburn: GekijÅban Hagane no Renkinjutsushi: Shanbara o Yuku Mono) is a 2005 Japanese animated film directed by Seiji Mizushima and written by Sho Aikawa.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Fullmetal Alchemist the Movie: Conqueror of Shamballa (Japanese: , Hepburn: GekijÅban Hagane no Renkinjutsushi: Shanbara o Yuku Mono) is a 2005 Japanese animated film directed by Seiji Mizushima and written by Sho Aikawa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Fullmetal Alchemist the Movie: Conqueror of Shamballa\", \"directed by\", \"Seiji Mizushima\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"directed by\",\n",
      "      \"support\": \"Seiji Mizushima and written by Sho Aikawa.\",\n",
      "      \"notes\": \"The subject and cue are explicitly mentioned in the text.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Fullmetal Alchemist the Movie: Conqueror of Shamballa\", \"written by\", \"Sho Aikawa\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"written by\",\n",
      "      \"support\": \"Seiji Mizushima and written by Sho Aikawa.\",\n",
      "      \"notes\": \"The subject and cue are explicitly mentioned in the text.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['Fullmetal Alchemist the Movie: Conqueror of Shamballa', 'directed by', 'Seiji Mizushima'], 'confidence': 1.0, 'cue': 'directed by', 'support': 'Seiji Mizushima and written by Sho Aikawa.', 'notes': 'The subject and cue are explicitly mentioned in the text.'}, {'triple': ['Fullmetal Alchemist the Movie: Conqueror of Shamballa', 'written by', 'Sho Aikawa'], 'confidence': 1.0, 'cue': 'written by', 'support': 'Seiji Mizushima and written by Sho Aikawa.', 'notes': 'The subject and cue are explicitly mentioned in the text.'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_11\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Alice's Wonderland is a 1923 Walt Disney short silent film, produced in Kansas City, Missouri.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Alice's Wonderland is a 1923 Walt Disney short silent film, produced in Kansas City, Missouri.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Alice's Wonderland\", \"narrative location\", \"Kansas City, Missouri\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"produced in\",\n",
      "      \"support\": \"produced in Kansas City, Missouri\",\n",
      "      \"notes\": \"The film is the subject, 'Kansas City, Missouri' is the object, and the cue 'produced in' connects them, indicating the 'narrative location' relation.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Alice's Wonderland\", \"filming location\", \"Kansas City, Missouri\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"produced in\",\n",
      "      \"support\": \"produced in Kansas City, Missouri\",\n",
      "      \"notes\": \"The film is the subject, 'Kansas City, Missouri' is the object, and the cue 'produced in' connects them, indicating the 'filming location' relation.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': [\"Alice's Wonderland\", 'narrative location', 'Kansas City, Missouri'], 'confidence': 1.0, 'cue': 'produced in', 'support': 'produced in Kansas City, Missouri', 'notes': \"The film is the subject, 'Kansas City, Missouri' is the object, and the cue 'produced in' connects them, indicating the 'narrative location' relation.\"}, {'triple': [\"Alice's Wonderland\", 'filming location', 'Kansas City, Missouri'], 'confidence': 1.0, 'cue': 'produced in', 'support': 'produced in Kansas City, Missouri', 'notes': \"The film is the subject, 'Kansas City, Missouri' is the object, and the cue 'produced in' connects them, indicating the 'filming location' relation.\"}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_12\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Welcome to Eltingville was written by Dorkin and Chuck Sheetz and received a positive reception.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Welcome to Eltingville was written by Dorkin and Chuck Sheetz and received a positive reception.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Welcome to Eltingville\", \"screenwriter\", \"Dorkin\"],\n",
      "      \"confidence\": 0.8,\n",
      "      \"cue\": \"written by\",\n",
      "      \"support\": \"written by Dorkin\",\n",
      "      \"notes\": \"The subject and object are both humans, which matches the domain and range for the screenwriter relation.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Welcome to Eltingville\", \"screenwriter\", \"Chuck Sheetz\"],\n",
      "      \"confidence\": 0.8,\n",
      "      \"cue\": \"written by\",\n",
      "      \"support\": \"written by Chuck Sheetz\",\n",
      "      \"notes\": \"The subject and object are both humans, which matches the domain and range for the screenwriter relation.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['Welcome to Eltingville', 'screenwriter', 'Dorkin'], 'confidence': 0.8, 'cue': 'written by', 'support': 'written by Dorkin', 'notes': 'The subject and object are both humans, which matches the domain and range for the screenwriter relation.'}, {'triple': ['Welcome to Eltingville', 'screenwriter', 'Chuck Sheetz'], 'confidence': 0.8, 'cue': 'written by', 'support': 'written by Chuck Sheetz', 'notes': 'The subject and object are both humans, which matches the domain and range for the screenwriter relation.'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_13\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"The Night of Taneyamagahara (, Taneyamagahara no Yoru) is a short anime film directed by Kazuo Oga and released by Studio Ghibli.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " The Night of Taneyamagahara (, Taneyamagahara no Yoru) is a short anime film directed by Kazuo Oga and released by Studio Ghibli.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"The Night of Taneyamagahara\", \"directed by\", \"Kazuo Oga\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"directed by\",\n",
      "      \"support\": \"The Night of Taneyamagahara no Yoru is a short anime film directed by Kazuo Oga.\",\n",
      "      \"notes\": \"domain/range check: film (subject) - human (range)\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"The Night of Taneyamagahara\", \"production company\", \"Studio Ghibli\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"released by\",\n",
      "      \"support\": \"released by Studio Ghibli.\",\n",
      "      \"notes\": \"domain/range check: film (subject) - film production company (range)\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['The Night of Taneyamagahara', 'directed by', 'Kazuo Oga'], 'confidence': 1.0, 'cue': 'directed by', 'support': 'The Night of Taneyamagahara no Yoru is a short anime film directed by Kazuo Oga.', 'notes': 'domain/range check: film (subject) - human (range)'}, {'triple': ['The Night of Taneyamagahara', 'production company', 'Studio Ghibli'], 'confidence': 1.0, 'cue': 'released by', 'support': 'released by Studio Ghibli.', 'notes': 'domain/range check: film (subject) - film production company (range)'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_14\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"\\\"The Magnificent World of El-Hazard\\\") is a Japanese anime franchise written by Ryoe Tsukimura and directed by Hiroki Hayashi.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " \"The Magnificent World of El-Hazard\") is a Japanese anime franchise written by Ryoe Tsukimura and directed by Hiroki Hayashi.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"The Magnificent World of El-Hazard\", \"directed\", \"Hiroki Hayashi\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"directed by\",\n",
      "      \"support\": \"\\\"The Magnificent World of El-Hazard\\\" is a Japanese anime franchise directed by Hiroki Hayashi.\",\n",
      "      \"notes\": \"domain/range check: film (subject) - human (range)\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"The Magnificent World of El-Hazard\", \"screenwriter\", \"Ryoe Tsukimura\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"written by\",\n",
      "      \"support\": \"\\\"The Magnificent World of El-Hazard\\\" is a Japanese anime franchise written by Ryoe Tsukimura.\",\n",
      "      \"notes\": \"domain/range check: film (subject) - human (range)\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['The Magnificent World of El-Hazard', 'directed', 'Hiroki Hayashi'], 'confidence': 1.0, 'cue': 'directed by', 'support': '\"The Magnificent World of El-Hazard\" is a Japanese anime franchise directed by Hiroki Hayashi.', 'notes': 'domain/range check: film (subject) - human (range)'}, {'triple': ['The Magnificent World of El-Hazard', 'screenwriter', 'Ryoe Tsukimura'], 'confidence': 1.0, 'cue': 'written by', 'support': '\"The Magnificent World of El-Hazard\" is a Japanese anime franchise written by Ryoe Tsukimura.', 'notes': 'domain/range check: film (subject) - human (range)'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_15\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Daicon III was made by Hideaki Anno, Hiroyuki Yamaga and Takami Akai and Daicon IV credits twelve people, including Yamaga as the director and Anno and Akai as animation supervisors.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Daicon III was made by Hideaki Anno, Hiroyuki Yamaga and Takami Akai and Daicon IV credits twelve people, including Yamaga as the director and Anno and Akai as animation supervisors.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Daicon III\", \"director\", \"Hiroyuki Yamaga\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"was made by\",\n",
      "      \"support\": \"Daicon III was made by Hideaki Anno, Hiroyuki Yamaga and Takami Akai\",\n",
      "      \"notes\": \"The subject and object are both films, and the cue 'was made by' indicates the director relation.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Daicon III\", \"director\", \"Hideaki Anno\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"was made by\",\n",
      "      \"support\": \"Daicon III was made by Hideaki Anno, Hiroyuki Yamaga and Takami Akai\",\n",
      "      \"notes\": \"The subject and object are both films, and the cue 'was made by' indicates the director relation.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Daicon III\", \"director\", \"Takami Akai\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"was made by\",\n",
      "      \"support\": \"Daicon III was made by Hideaki Anno, Hiroyuki Yamaga and Takami Akai\",\n",
      "      \"notes\": \"The subject and object are both films, and the cue 'was made by' indicates the director relation.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Daicon IV\", \"director\", \"Hiroyuki Yamaga\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"as the director\",\n",
      "      \"support\": \"Yamaga as the director\",\n",
      "      \"notes\": \"The subject and object are both films, and the cue 'as the director' indicates the director relation.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Daicon IV\", \"animation supervisor\", \"Hiroyuki Yamaga\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"animation supervisors\",\n",
      "      \"support\": \"twelve people, including Yamaga as the director and Anno and Akai as animation supervisors\",\n",
      "      \"notes\": \"The subject and object are both films, and the cue 'animation supervisors' indicates the animation supervisor relation.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Daicon IV\", \"animation supervisor\", \"Anno\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"animation supervisors\",\n",
      "      \"support\": \"twelve people, including Yamaga as the director and Anno and Akai as animation supervisors\",\n",
      "      \"notes\": \"The subject and object are both films, and the cue 'animation supervisors' indicates the animation supervisor relation.\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Daicon IV\", \"animation supervisor\", \"Takami Akai\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"animation supervisors\",\n",
      "      \"support\": \"twelve people, including Yamaga as the director and Anno and Akai as animation supervisors\",\n",
      "      \"notes\": \"The subject and object are both films, and the cue 'animation supervisors' indicates the animation supervisor relation.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['Daicon III', 'director', 'Hiroyuki Yamaga'], 'confidence': 1.0, 'cue': 'was made by', 'support': 'Daicon III was made by Hideaki Anno, Hiroyuki Yamaga and Takami Akai', 'notes': \"The subject and object are both films, and the cue 'was made by' indicates the director relation.\"}, {'triple': ['Daicon III', 'director', 'Hideaki Anno'], 'confidence': 1.0, 'cue': 'was made by', 'support': 'Daicon III was made by Hideaki Anno, Hiroyuki Yamaga and Takami Akai', 'notes': \"The subject and object are both films, and the cue 'was made by' indicates the director relation.\"}, {'triple': ['Daicon III', 'director', 'Takami Akai'], 'confidence': 1.0, 'cue': 'was made by', 'support': 'Daicon III was made by Hideaki Anno, Hiroyuki Yamaga and Takami Akai', 'notes': \"The subject and object are both films, and the cue 'was made by' indicates the director relation.\"}, {'triple': ['Daicon IV', 'director', 'Hiroyuki Yamaga'], 'confidence': 1.0, 'cue': 'as the director', 'support': 'Yamaga as the director', 'notes': \"The subject and object are both films, and the cue 'as the director' indicates the director relation.\"}, {'triple': ['Daicon IV', 'animation supervisor', 'Hiroyuki Yamaga'], 'confidence': 1.0, 'cue': 'animation supervisors', 'support': 'twelve people, including Yamaga as the director and Anno and Akai as animation supervisors', 'notes': \"The subject and object are both films, and the cue 'animation supervisors' indicates the animation supervisor relation.\"}, {'triple': ['Daicon IV', 'animation supervisor', 'Anno'], 'confidence': 1.0, 'cue': 'animation supervisors', 'support': 'twelve people, including Yamaga as the director and Anno and Akai as animation supervisors', 'notes': \"The subject and object are both films, and the cue 'animation supervisors' indicates the animation supervisor relation.\"}, {'triple': ['Daicon IV', 'animation supervisor', 'Takami Akai'], 'confidence': 1.0, 'cue': 'animation supervisors', 'support': 'twelve people, including Yamaga as the director and Anno and Akai as animation supervisors', 'notes': \"The subject and object are both films, and the cue 'animation supervisors' indicates the animation supervisor relation.\"}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_16\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"The Disappearance of Haruhi Suzumiya is produced by Kyoto Animation, written by Fumihiko Shimo and directed by Tatsuya Ishihara and Yasuhiro Takemoto.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " The Disappearance of Haruhi Suzumiya is produced by Kyoto Animation, written by Fumihiko Shimo and directed by Tatsuya Ishihara and Yasuhiro Takemoto.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"The Disappearance of Haruhi Suzumiya\", \"directed\", \"Tatsuya Ishihara and Yasuhiro Takemoto\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"directed by\",\n",
      "      \"support\": \"The Disappearance of Haruhi Suzumiya is directed by Tatsuya Ishihara and Yasuhiro Takemoto.\",\n",
      "      \"notes\": \"domain/range check: human (director) and film\"\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"The Disappearance of Haruhi Suzumiya\", \"screenwriter\", \"Fumihiko Shimo\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"written by\",\n",
      "      \"support\": \"The Disappearance of Haruhi Suzumiya is written by Fumihiko Shimo.\",\n",
      "      \"notes\": \"domain/range check: human (screenwriter) and film\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['The Disappearance of Haruhi Suzumiya', 'directed', 'Tatsuya Ishihara and Yasuhiro Takemoto'], 'confidence': 1.0, 'cue': 'directed by', 'support': 'The Disappearance of Haruhi Suzumiya is directed by Tatsuya Ishihara and Yasuhiro Takemoto.', 'notes': 'domain/range check: human (director) and film'}, {'triple': ['The Disappearance of Haruhi Suzumiya', 'screenwriter', 'Fumihiko Shimo'], 'confidence': 1.0, 'cue': 'written by', 'support': 'The Disappearance of Haruhi Suzumiya is written by Fumihiko Shimo.', 'notes': 'domain/range check: human (screenwriter) and film'}]}\n",
      "\n",
      "[P2 WRITE] 16 rows -> /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt2/wikidata/ont_1_movie_output_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# BLOCK 9: MANUAL TEST RUN (single file Prompt 2)\n",
    "########################################\n",
    "\n",
    "run_pipeline_prompt2(\n",
    "    ontology_path=ONTOLOGY_JSON,\n",
    "    input_jsonl_path=INPUT_JSONL,\n",
    "    output_jsonl_path=OUTPUT_JSONL,\n",
    "    k_triples=K_TRIPLES,\n",
    "    max_items=MAX_ITEMS,\n",
    "    verbose=VERBOSE,   #True for first check\n",
    "    model_id=MODEL_ID,\n",
    "    generator=None,\n",
    "    tokenizer=None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee295023-5e21-4372-b31f-6442bbd86140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc23898c-aef2-4536-af9c-409d998f5a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d47ae3f-d3ee-487d-b006-b81cb50165ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "PATTERN = re.compile(r\"^ont_(\\d+)_([a-zA-Z0-9]+)_test\\.jsonl$\")\n",
    "\n",
    "def make_paths(filename: str, base_input: str, base_onto: str, base_out: str):\n",
    "    \"\"\"\n",
    "    Given something like 'ont_8_politician_test.jsonl', build:\n",
    "      - input_jsonl_path      -> <base_input>/ont_8_politician_test.jsonl\n",
    "      - ontology_json_path    -> <base_onto>/8_politician_ontology.json\n",
    "      - output_jsonl_path     -> <base_out>/ont_8_politician_output.jsonl\n",
    "      - tag                   -> 'ont_8_politician'\n",
    "    \"\"\"\n",
    "    m = PATTERN.match(filename)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unexpected filename format: {filename}\")\n",
    "    idx, cat = m.groups()\n",
    "\n",
    "    input_jsonl_path = os.path.join(base_input, filename)\n",
    "    ontology_json_path = os.path.join(base_onto, f\"{idx}_{cat}_ontology.json\")\n",
    "\n",
    "    out_name = filename.replace(\"_test.jsonl\", \"_output.jsonl\")\n",
    "    output_jsonl_path = os.path.join(base_out, out_name)\n",
    "\n",
    "    tag = f\"ont_{idx}_{cat}\"\n",
    "    return input_jsonl_path, ontology_json_path, output_jsonl_path, tag\n",
    "\n",
    "\n",
    "def run_wikidata_batch_p2(verbose: bool = True):\n",
    "    BASE_INPUT = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_text/\"\n",
    "    BASE_ONTO  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/\"\n",
    "    BASE_OUT   = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt2/wikidata/\"\n",
    "\n",
    "    FILENAMES = [\n",
    "        \"ont_1_movie_test.jsonl\",\n",
    "        \"ont_2_music_test.jsonl\",\n",
    "        \"ont_3_sport_test.jsonl\",\n",
    "        \"ont_4_book_test.jsonl\",\n",
    "        \"ont_5_military_test.jsonl\",\n",
    "        \"ont_6_building_test.jsonl\",\n",
    "        \"ont_7_tv_test.jsonl\",\n",
    "        \"ont_8_politician_test.jsonl\",\n",
    "        \"ont_9_organization_test.jsonl\",\n",
    "        \"ont_10_airport_test.jsonl\",\n",
    "    ]\n",
    "\n",
    "    os.makedirs(BASE_OUT, exist_ok=True)\n",
    "\n",
    "    # 1. load the model ONCE and reuse it for all files\n",
    "    generator, tokenizer = setup_model(model_id=MODEL_ID)\n",
    "\n",
    "    # 2. loop over all files\n",
    "    for fname in FILENAMES:\n",
    "        try:\n",
    "            # build all required paths for this file using the shared logic\n",
    "            input_jsonl_path, ontology_json_path, output_jsonl_path, tag = make_paths(\n",
    "                filename=fname,\n",
    "                base_input=BASE_INPUT,\n",
    "                base_onto=BASE_ONTO,\n",
    "                base_out=BASE_OUT,\n",
    "            )\n",
    "\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(f\"[RUN P2] wikidata {tag}\")\n",
    "            print(f\"[INPUT ] {input_jsonl_path}\")\n",
    "            print(f\"[ONTO  ] {ontology_json_path}\")\n",
    "            print(f\"[OUTPUT] {output_jsonl_path}\")\n",
    "\n",
    "            # 3. run the single-file pipeline, reusing the loaded model\n",
    "            run_pipeline_prompt2(\n",
    "                ontology_path=ontology_json_path,\n",
    "                input_jsonl_path=input_jsonl_path,\n",
    "                output_jsonl_path=output_jsonl_path,\n",
    "                k_triples=K_TRIPLES,\n",
    "                max_items=None,\n",
    "                verbose=False,\n",
    "                model_id=MODEL_ID,\n",
    "                generator=generator,   # reuse\n",
    "                tokenizer=tokenizer,   # reuse\n",
    "            )\n",
    "\n",
    "            print(f\"[DONE P2] wikidata {tag}\")\n",
    "\n",
    "        except Exception as exc:\n",
    "            print(f\"[ERROR P2] wikidata {fname}: {exc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0032ed-4311-4abf-aa49-ee532b2f43d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] model=mistralai/Mistral-7B-Instruct-v0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c2a70ab30346e392866083a7d3e94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[RUN P2] wikidata ont_1_movie\n",
      "[INPUT ] /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_text/ont_1_movie_test.jsonl\n",
      "[ONTO  ] /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/1_movie_ontology.json\n",
      "[OUTPUT] /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt2/wikidata/ont_1_movie_output.jsonl\n",
      "======================================\n",
      "[ID] ont_1_movie_test_1\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Bleach: Hell Verse (Japanese: BLEACH , Hepburn: BurÄ«chi Jigoku-Hen) is a 2010 Japanese animated film directed by Noriyuki Abe.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Bleach: Hell Verse (Japanese: BLEACH , Hepburn: BurÄ«chi Jigoku-Hen) is a 2010 Japanese animated film directed by Noriyuki Abe.\n",
      "[RAW RESPONSE]\n",
      " {\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Bleach: Hell Verse\", \"directed by\", \"Noriyuki Abe\"],\n",
      "      \"confidence\": 1.0,\n",
      "      \"cue\": \"directed by\",\n",
      "      \"support\": \"Noriyuki Abe\",\n",
      "      \"notes\": \"domain/range check: film (subject) - human (range)\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[PARSED JSON]\n",
      " {'triples': [{'triple': ['Bleach: Hell Verse', 'directed by', 'Noriyuki Abe'], 'confidence': 1.0, 'cue': 'directed by', 'support': 'Noriyuki Abe', 'notes': 'domain/range check: film (subject) - human (range)'}]}\n",
      "======================================\n",
      "[ID] ont_1_movie_test_2\n",
      "[TEXT_KEY] sent\n",
      "[SYSTEM PROMPT]\n",
      " You are a KG triple extractor. Match relation cues in the text and return only triples that satisfy the ontology’s domain→range. Cite exact evidence. Output JSON only.\n",
      "[USER PROMPT]\n",
      "     Task: Using explicit lexical cues found in the text, extract up to 1 triples [subject, relation, object].\n",
      "    Enforce ontology domain→range strictly; if a triple is invalid, omit it.\n",
      "\n",
      "    CUE GENERATION GUIDANCE:\n",
      "    - A lexical cue is a word or short phrase in the text that directly connects the subject and object\n",
      "      and signals the relation between them.\n",
      "    - It can be a **verb**, **verb phrase**, or **prepositional phrase** such as:\n",
      "        \"directed by\", \"founded in\", \"built by\", \"located in\", \"written by\", \"headed by\".\n",
      "      These are only illustrative examples — you must infer the appropriate cue for each relation label and sentence.\n",
      "    - The cue MUST appear literally in the text and should sit between, or very near, the subject and object mentions.\n",
      "    - The cue expresses the natural-language realization of the ontology relation.\n",
      "    - If no such linking phrase appears in the text for a given relation, skip that relation.\n",
      "    - Do NOT invent cues or use world knowledge; work only from the surface text.\n",
      "\n",
      "    PROCEDURE:\n",
      "    1. Identify candidate subjects and objects that match ontology domain and range types.\n",
      "    2. Locate a surface phrase that connects them and expresses the ontology relation label.\n",
      "    3. Record that phrase as the \"cue\" and quote the full supporting span that contains it.\n",
      "    4. If none is found, do not emit a triple for that relation.\n",
      "    5. Resolve simple pronouns only if doing so maintains correct domain→range typing.\n",
      "\n",
      "    Text:\n",
      "    \"Keyboard Cat's original form was a video originally made in 1984 by Charlie Schmidt of his cat Fatso seemingly playing a piano (though manipulated by Schmidt off-camera) to a cheery tune.\"\n",
      "\n",
      "    Ontology concepts:\n",
      "    - human\n",
      "- city\n",
      "- country\n",
      "- film\n",
      "- film genre\n",
      "- genre\n",
      "- film production company\n",
      "- film award\n",
      "- award\n",
      "- written work\n",
      "- film character\n",
      "- film organization\n",
      "\n",
      "    Ontology relations (domain → range):\n",
      "    - director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "    Output JSON only in this exact schema:\n",
      "    {\n",
      "      \"triples\": [\n",
      "        {\n",
      "          \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "          \"confidence\": 0.0,  // confidence 0–1\n",
      "          \"cue\": \"matched cue phrase from text\",\n",
      "          \"support\": \"exact quoted span(s)\",\n",
      "          \"notes\": \"domain/range check; or pronoun resolution note if applied\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "\n",
      "    Rules:\n",
      "    - Work only from visible text evidence.\n",
      "    - If no relation cue appears, return an empty list of triples.\n",
      "    - Do NOT invent or assume facts not in text.\n",
      "    - Always quote exact spans for support and cue.\n",
      "\n",
      "[SOURCE TEXT]\n",
      " Keyboard Cat's original form was a video originally made in 1984 by Charlie Schmidt of his cat Fatso seemingly playing a piano (though manipulated by Schmidt off-camera) to a cheery tune.\n"
     ]
    }
   ],
   "source": [
    "run_wikidata_batch_p2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ea626-c6fb-410b-be81-e956ed6bee0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44837244-337c-4b84-847a-3189883ba13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c30802-738f-4025-bb55-1ebb39d8f424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ae95b-398d-40b0-b7a8-5d4ecf67f700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54e6404b-0132-4ce3-b3c2-9ed81ea1738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "DBPEDIA_PATTERN = re.compile(r\"^ont_(\\d+)_([a-zA-Z0-9]+)_test\\.jsonl$\")\n",
    "\n",
    "def make_dbpedia_paths(filename: str, base_input: str, base_onto: str, base_out: str):\n",
    "    \"\"\"\n",
    "    Given 'ont_14_writtenwork_test.jsonl', return:\n",
    "      - input_jsonl_path      -> <base_input>/ont_14_writtenwork_test.jsonl\n",
    "      - ontology_json_path    -> <base_onto>/14_writtenwork_ontology.json\n",
    "      - output_jsonl_path     -> <base_out>/ont_14_writtenwork_output.jsonl\n",
    "      - tag                   -> 'ont_14_writtenwork'\n",
    "    \"\"\"\n",
    "    m = DBPEDIA_PATTERN.match(filename)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unexpected filename format: {filename}\")\n",
    "    idx, cat = m.groups()\n",
    "\n",
    "    input_jsonl_path = os.path.join(base_input, filename)\n",
    "    ontology_json_path = os.path.join(base_onto, f\"{idx}_{cat}_ontology.json\")\n",
    "    out_name = filename.replace(\"_test.jsonl\", \"_output.jsonl\")\n",
    "    output_jsonl_path = os.path.join(base_out, out_name)\n",
    "\n",
    "    tag = f\"ont_{idx}_{cat}\"\n",
    "    return input_jsonl_path, ontology_json_path, output_jsonl_path, tag\n",
    "\n",
    "\n",
    "def run_dbpedia_batch_p2(verbose: bool = True):\n",
    "    BASE_INPUT = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_text/\"\n",
    "    BASE_ONTO  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/\"\n",
    "    BASE_OUT   = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt2/dbpedia/\"\n",
    "\n",
    "    FILENAMES = [\n",
    "        \"ont_12_monument_test.jsonl\",\n",
    "        \"ont_1_university_test.jsonl\",\n",
    "        \"ont_10_comicscharacter_test.jsonl\",\n",
    "        \"ont_11_meanoftransportation_test.jsonl\",\n",
    "        \"ont_13_food_test.jsonl\",\n",
    "        \"ont_14_writtenwork_test.jsonl\",\n",
    "        \"ont_15_software_test.jsonl\",\n",
    "        \"ont_16_person_test.jsonl\",\n",
    "        \"ont_17_athlete_test.jsonl\",\n",
    "        \"ont_18_organization_test.jsonl\",\n",
    "        \"ont_19_film_test.jsonl\",\n",
    "    ]\n",
    "\n",
    "    os.makedirs(BASE_OUT, exist_ok=True)\n",
    "\n",
    "    # 1. load the model ONCE and reuse it for all dbpedia files\n",
    "    generator, tokenizer = setup_model(model_id=MODEL_ID)\n",
    "\n",
    "    # 2. iterate over each file\n",
    "    for fname in FILENAMES:\n",
    "        try:\n",
    "            # construct all paths for this file\n",
    "            input_jsonl_path, ontology_json_path, output_jsonl_path, tag = make_dbpedia_paths(\n",
    "                filename=fname,\n",
    "                base_input=BASE_INPUT,\n",
    "                base_onto=BASE_ONTO,\n",
    "                base_out=BASE_OUT,\n",
    "            )\n",
    "\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(f\"[RUN P2] dbpedia {tag}\")\n",
    "            print(f\"[INPUT ] {input_jsonl_path}\")\n",
    "            print(f\"[ONTO  ] {ontology_json_path}\")\n",
    "            print(f\"[OUTPUT] {output_jsonl_path}\")\n",
    "\n",
    "            # 3. call the single-file pipeline, reusing the SAME model\n",
    "            run_pipeline_prompt2(\n",
    "                ontology_path=ontology_json_path,\n",
    "                input_jsonl_path=input_jsonl_path,\n",
    "                output_jsonl_path=output_jsonl_path,\n",
    "                k_triples=K_TRIPLES,\n",
    "                max_items=None,\n",
    "                verbose=False,\n",
    "                model_id=MODEL_ID,\n",
    "                generator=generator,   # reuse the already-loaded model\n",
    "                tokenizer=tokenizer,   # reuse tokenizer\n",
    "            )\n",
    "\n",
    "            print(f\"[DONE P2] dbpedia {tag}\")\n",
    "\n",
    "        except Exception as exc:\n",
    "            print(f\"[ERROR P2] dbpedia {fname}: {exc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c52a65-8050-4eb5-90f4-0d14fb9df21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] model=mistralai/Mistral-7B-Instruct-v0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81432bf07c8c4069b74fe7b5ef55fa16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[RUN P2] dbpedia ont_12_monument\n",
      "[INPUT ] /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_text/ont_12_monument_test.jsonl\n",
      "[ONTO  ] /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/12_monument_ontology.json\n",
      "[OUTPUT] /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt2/dbpedia/ont_12_monument_output.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE P2] dbpedia ont_12_monument\n",
      "\n",
      "================================================================================\n",
      "[RUN P2] dbpedia ont_1_university\n",
      "[INPUT ] /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_text/ont_1_university_test.jsonl\n",
      "[ONTO  ] /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/1_university_ontology.json\n",
      "[OUTPUT] /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt2/dbpedia/ont_1_university_output.jsonl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# FULL DATASET BATCH RUNS\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mrun_dbpedia_batch_p2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 70\u001b[0m, in \u001b[0;36mrun_dbpedia_batch_p2\u001b[0;34m(verbose)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[OUTPUT] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_jsonl_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# 3. call the single-file pipeline, reusing the SAME model\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[43mrun_pipeline_prompt2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43montology_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43montology_json_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_jsonl_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_jsonl_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_jsonl_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_jsonl_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK_TRIPLES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# reuse the already-loaded model\u001b[39;49;00m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# reuse tokenizer\u001b[39;49;00m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DONE P2] dbpedia \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "Cell \u001b[0;32mIn[10], line 57\u001b[0m, in \u001b[0;36mrun_pipeline_prompt2\u001b[0;34m(ontology_path, input_jsonl_path, output_jsonl_path, k_triples, max_items, verbose, model_id, generator, tokenizer)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[USER PROMPT]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, usr_prompt)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[SOURCE TEXT]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, text_val)\n\u001b[0;32m---> 57\u001b[0m raw_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_raw_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musr_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m parsed_json \u001b[38;5;241m=\u001b[39m try_parse_json(raw_response)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m, in \u001b[0;36mgenerate_raw_json\u001b[0;34m(generator, tokenizer, system_prompt, user_prompt, max_new_tokens, temperature, top_p)\u001b[0m\n\u001b[1;32m     18\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     19\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt},\n\u001b[1;32m     20\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt},\n\u001b[1;32m     21\u001b[0m ]\n\u001b[1;32m     23\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     24\u001b[0m     messages,\n\u001b[1;32m     25\u001b[0m     tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_full_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# HF pipeline returns list[{\"generated_text\": \"...\"}]\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:302\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/pipelines/base.py:1431\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1424\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1425\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         )\n\u001b[1;32m   1429\u001b[0m     )\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/pipelines/base.py:1438\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1437\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1438\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/pipelines/base.py:1338\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1336\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1337\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1338\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:400\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    398\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 400\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[1;32m    403\u001b[0m     generated_sequence \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msequences\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/generation/utils.py:2597\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2589\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2590\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2591\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2592\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2593\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2594\u001b[0m     )\n\u001b[1;32m   2596\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2597\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2598\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2608\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2610\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2611\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2612\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2613\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2614\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/generation/utils.py:3560\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3558\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3560\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3562\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3563\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3564\u001b[0m     outputs,\n\u001b[1;32m   3565\u001b[0m     model_kwargs,\n\u001b[1;32m   3566\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3567\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/accelerate/hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/utils/generic.py:969\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    971\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:690\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    686\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    687\u001b[0m )\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 690\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    704\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/utils/generic.py:969\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    971\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:423\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    421\u001b[0m     all_hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[0;32m--> 423\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/modeling_layers.py:48\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/accelerate/hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:260\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    259\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 260\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    263\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/accelerate/hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:54\u001b[0m, in \u001b[0;36mMistralMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 54\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 170\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/accelerate/hooks.py:360\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    353\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    354\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    357\u001b[0m         ):\n\u001b[1;32m    358\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 360\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    370\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    371\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/kg_pipeline/lib/python3.10/site-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# FULL DATASET BATCH RUNS\n",
    "########################################\n",
    "run_dbpedia_batch_p2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c632b8-f94f-490a-ab06-ef57d26fdb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_pipeline",
   "language": "python",
   "name": "kg_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
