{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e343910",
   "metadata": {},
   "source": [
    "\n",
    "# Triple Extraction Evaluation — Monument Ontology\n",
    "\n",
    "This notebook evaluates **predicted triples** against **ground-truth triples** for the *Monument* ontology.\n",
    "- **Triples-only** scoring (no mentions/spans).\n",
    "- Exact-match after light normalization (lowercase; remove spaces/underscores).\n",
    "- Reports **per-example** metrics and **aggregate** (macro & micro) precision/recall/F1.\n",
    "- No relation filtering and no \"selected IDs\" logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb30d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Set\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6cad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File configuration — adjust as needed\n",
    "ONTOLOGY_PATH = Path('/mnt/data/12_monument_ontology.json')\n",
    "SYSTEM_OUTPUT_PATH = Path('/mnt/data/ont_12_monument_output.jsonl')\n",
    "GROUND_TRUTH_PATH = Path('/mnt/data/ont_12_monument_ground_truth.jsonl')\n",
    "\n",
    "# Output paths\n",
    "PER_EXAMPLE_OUT = Path('/mnt/data/eval_monument_per_example.jsonl')\n",
    "AGGREGATE_OUT = Path('/mnt/data/eval_monument_aggregate.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I/O helpers\n",
    "def read_jsonl(path: Path) -> List[Dict]:\n",
    "    data = []\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "def write_jsonl(items: List[Dict], path: Path) -> None:\n",
    "    with path.open('w', encoding='utf-8') as f:\n",
    "        for it in items:\n",
    "            f.write(json.dumps(it, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def write_json(obj: Dict, path: Path) -> None:\n",
    "    with path.open('w', encoding='utf-8') as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalization utilities\n",
    "_WS_UNDERSCORE = re.compile(r'(_|\\s+)')\n",
    "\n",
    "def norm_value(text: str) -> str:\n",
    "    if text is None:\n",
    "        return ''\n",
    "    # remove spaces/underscores and lowercase\n",
    "    return _WS_UNDERSCORE.sub('', str(text)).lower()\n",
    "\n",
    "def norm_triple(sub: str, rel: str, obj: str) -> Tuple[str, str, str]:\n",
    "    return (norm_value(sub), norm_value(rel), norm_value(obj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952cef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Metrics helpers\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class PRF:\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "    tp: int\n",
    "    fp: int\n",
    "    fn: int\n",
    "\n",
    "def prf_from_sets(gold: Set[Tuple[str,str,str]], pred: Set[Tuple[str,str,str]]) -> PRF:\n",
    "    tp = len(gold & pred)\n",
    "    fp = len(pred - gold)\n",
    "    fn = len(gold - pred)\n",
    "    denom_p = tp + fp\n",
    "    denom_r = tp + fn\n",
    "    precision = tp/denom_p if denom_p > 0 else (1.0 if len(gold)==0 else 0.0)\n",
    "    recall = tp/denom_r if denom_r > 0 else 1.0\n",
    "    f1 = (2*precision*recall/(precision+recall)) if (precision+recall)>0 else 0.0\n",
    "    return PRF(precision, recall, f1, tp, fp, fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract triples from system & gold records\n",
    "\n",
    "def extract_system_triples(rec: Dict) -> List[Tuple[str,str,str]]:\n",
    "    \"\"\"Return list of raw (sub, rel, obj) from system record. Skip entries with null object.\"\"\"\n",
    "    out = []\n",
    "    resp = rec.get('response', {})\n",
    "    j = resp.get('json')\n",
    "    if isinstance(j, dict):\n",
    "        for tr in j.get('triples', []):\n",
    "            triple = tr.get('triple')\n",
    "            if (isinstance(triple, list) or isinstance(triple, tuple)) and len(triple) == 3:\n",
    "                s, r, o = triple\n",
    "                if o is None or s is None or r is None:\n",
    "                    continue\n",
    "                out.append((str(s), str(r), str(o)))\n",
    "    return out\n",
    "\n",
    "def extract_gold_triples(rec: Dict) -> List[Tuple[str,str,str]]:\n",
    "    out = []\n",
    "    for tr in rec.get('triples', []):\n",
    "        s = tr.get('sub')\n",
    "        r = tr.get('rel')\n",
    "        o = tr.get('obj')\n",
    "        if s is None or r is None or o is None:\n",
    "            continue\n",
    "        out.append((str(s), str(r), str(o)))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation core\n",
    "def evaluate(system_recs: List[Dict], gold_recs: List[Dict]) -> Dict:\n",
    "    sys_by_id = {r.get('id'): r for r in system_recs}\n",
    "    gold_by_id = {r.get('id'): r for r in gold_recs}\n",
    "    \n",
    "    ids = sorted(set(sys_by_id.keys()) & set(gold_by_id.keys()))\n",
    "    missing_sys = sorted(set(gold_by_id.keys()) - set(sys_by_id.keys()))\n",
    "    missing_gold = sorted(set(sys_by_id.keys()) - set(gold_by_id.keys()))\n",
    "    \n",
    "    per_items = []\n",
    "    micro_tp = micro_fp = micro_fn = 0\n",
    "    \n",
    "    for sid in ids:\n",
    "        sys_tr_raw = extract_system_triples(sys_by_id[sid])\n",
    "        gt_tr_raw = extract_gold_triples(gold_by_id[sid])\n",
    "        \n",
    "        sys_tr = {norm_triple(*t) for t in sys_tr_raw}\n",
    "        gt_tr  = {norm_triple(*t) for t in gt_tr_raw}\n",
    "        \n",
    "        prf = prf_from_sets(gt_tr, sys_tr)\n",
    "        micro_tp += prf.tp\n",
    "        micro_fp += prf.fp\n",
    "        micro_fn += prf.fn\n",
    "        \n",
    "        per_items.append({\n",
    "            \"id\": sid,\n",
    "            \"pred_count\": len(sys_tr),\n",
    "            \"gold_count\": len(gt_tr),\n",
    "            \"precision\": prf.precision,\n",
    "            \"recall\": prf.recall,\n",
    "            \"f1\": prf.f1,\n",
    "            \"tp\": prf.tp,\n",
    "            \"fp\": prf.fp,\n",
    "            \"fn\": prf.fn\n",
    "        })\n",
    "    \n",
    "    n = len(per_items)\n",
    "    macro = {\n",
    "        \"precision\": sum(d[\"precision\"] for d in per_items)/n if n else 0.0,\n",
    "        \"recall\":    sum(d[\"recall\"]    for d in per_items)/n if n else 0.0,\n",
    "        \"f1\":        sum(d[\"f1\"]        for d in per_items)/n if n else 0.0,\n",
    "    }\n",
    "    \n",
    "    denom_p = micro_tp + micro_fp\n",
    "    denom_r = micro_tp + micro_fn\n",
    "    micro_precision = micro_tp/denom_p if denom_p>0 else 1.0 if (micro_tp+micro_fn)==0 else 0.0\n",
    "    micro_recall    = micro_tp/denom_r if denom_r>0 else 1.0\n",
    "    micro_f1 = (2*micro_precision*micro_recall/(micro_precision+micro_recall)) if (micro_precision+micro_recall)>0 else 0.0\n",
    "    \n",
    "    aggregate = {\n",
    "        \"macro\": macro,\n",
    "        \"micro\": {\n",
    "            \"precision\": micro_precision,\n",
    "            \"recall\": micro_recall,\n",
    "            \"f1\": micro_f1,\n",
    "            \"tp\": micro_tp,\n",
    "            \"fp\": micro_fp,\n",
    "            \"fn\": micro_fn\n",
    "        },\n",
    "        \"counts\": {\n",
    "            \"evaluated_examples\": n,\n",
    "            \"missing_in_system\": len(missing_sys),\n",
    "            \"missing_in_gold\": len(missing_gold)\n",
    "        },\n",
    "        \"missing_ids\": {\n",
    "            \"in_system_only\": missing_gold,\n",
    "            \"in_gold_only\": missing_sys\n",
    "        }\n",
    "    }\n",
    "    return {\"per_items\": per_items, \"aggregate\": aggregate}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22152d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run evaluation\n",
    "system_recs = read_jsonl(SYSTEM_OUTPUT_PATH)\n",
    "gold_recs = read_jsonl(GROUND_TRUTH_PATH)\n",
    "\n",
    "results = evaluate(system_recs, gold_recs)\n",
    "\n",
    "# Save outputs\n",
    "write_jsonl(results[\"per_items\"], PER_EXAMPLE_OUT)\n",
    "write_json(results[\"aggregate\"], AGGREGATE_OUT)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - Per-example:\", PER_EXAMPLE_OUT)\n",
    "print(\" - Aggregate  :\", AGGREGATE_OUT)\n",
    "results[\"aggregate\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9194c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Top-5 hardest examples by F1 (ascending)\n",
    "hard = sorted(results[\"per_items\"], key=lambda d: d[\"f1\"])[:5]\n",
    "hard\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
