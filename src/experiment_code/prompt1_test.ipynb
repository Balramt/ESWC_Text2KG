{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2ac150-7c4e-40be-bc2b-4cabc7bf292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 21 12:30:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:81:00.0 Off |                  N/A |\n",
      "|  0%   41C    P8             31W /  370W |       2MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faac2d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limbo\n",
      "/opt/miniforge3/envs/jupyterhub/bin/python\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "!hostname\n",
    "!which python\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce28d5-4942-4b63-ab7a-bc6b0dc08f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 2816519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875a19aa-09d0-4c5a-a03e-afb8c9e8dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 0 — Imports & Config\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from textwrap import dedent\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "\n",
    "# Toggle: include \"mentions\" in final output JSONL (set False to match existing shape strictly)\n",
    "OUTPUT_MENTIONS = False\n",
    "\n",
    "\n",
    "def setup_model(model_id: str = \"mistralai/Mistral-7B-Instruct-v0.3\"):\n",
    "    print(\"⏳ Loading model:\", model_id)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "    model.config.use_cache = True  # KV caching is fine.\n",
    "\n",
    "    generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    return generator, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e84927a6-0c9e-42a1-8e12-939ab1a6f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 1 — IO Utilities (JSONL, few-shot loader)\n",
    "\n",
    "def read_jsonl(path, max_items: int | None = None):\n",
    "    \"\"\"Yield JSON objects from .jsonl; stop after max_items if provided.\"\"\"\n",
    "    count = 0\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            yield json.loads(line)\n",
    "            count += 1\n",
    "            if max_items is not None and count >= max_items:\n",
    "                break\n",
    "\n",
    "\n",
    "def write_jsonl(path, records):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for rec in records:\n",
    "            f.write(json.dumps(rec, ensure_ascii=False))\n",
    "            f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd5809da-25c9-4d8f-85f5-1b24377e3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2 — Ontology Helpers (labels, formatting)\n",
    "\n",
    "def _concept_label(ontology_json, qid):\n",
    "    \"\"\"\n",
    "    Map a concept qid to its human-readable label (string). If qid is already a label, return as-is.\n",
    "    \"\"\"\n",
    "    # Accept label passthrough\n",
    "    if isinstance(qid, str) and not qid.startswith(\"Q\"):\n",
    "        return qid\n",
    "    for c in ontology_json.get(\"concepts\", []):\n",
    "        if c.get(\"qid\") == qid:\n",
    "            return c.get(\"label\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def format_ontology_concepts(ontology_json):\n",
    "    return \", \".join(c.get(\"label\", \"\") for c in ontology_json.get(\"concepts\", []))\n",
    "\n",
    "\n",
    "def format_ontology_relations(ontology_json):\n",
    "    lines = []\n",
    "    for r in ontology_json.get(\"relations\", []):\n",
    "        dom = _concept_label(ontology_json, r.get(\"domain\"))\n",
    "        rng = _concept_label(ontology_json, r.get(\"range\"))\n",
    "        lines.append(f'- {r.get(\"label\")}({dom},{rng})')\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def build_relation_sig_maps(ontology_json):\n",
    "    \"\"\"\n",
    "    Return mapping: relation_label -> (domain_label, range_label)\n",
    "    \"\"\"\n",
    "    rel2dom = {}\n",
    "    rel2rng = {}\n",
    "    for r in ontology_json.get(\"relations\", []):\n",
    "        label = r.get(\"label\")\n",
    "        dom = _concept_label(ontology_json, r.get(\"domain\")) or r.get(\"domain\")\n",
    "        rng = _concept_label(ontology_json, r.get(\"range\")) or r.get(\"range\")\n",
    "        if label:\n",
    "            rel2dom[label] = dom\n",
    "            rel2rng[label] = rng\n",
    "    return rel2dom, rel2rng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff2d3f7d-2b7c-4a3b-b10b-78e70d899982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3 — Prompt 1 Builder (JSON-only: mentions + triples)\n",
    "\n",
    "from typing import Dict, Any, Optional\n",
    "import json\n",
    "\n",
    "def _escape_multiline(s: str) -> str:\n",
    "    return s.replace(\"\\\\\", \"\\\\\\\\\").replace('\"', '\\\\\"')\n",
    "\n",
    "def build_prompt1_json_only(\n",
    "    ontology_json: Dict[str, Any],\n",
    "    test_sentence: str,\n",
    "    k: int = 6,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build Prompt 1 instruction that returns a single JSON object with fields:\n",
    "      mentions[], triples[].\n",
    "\n",
    "    The triples schema is aligned to the evaluator:\n",
    "      - subject_type / object_type\n",
    "      - confidence_prompt\n",
    "      - support as a list of {quote, char_span}\n",
    "      - ontology_domain_range_check (the model may set it; we recompute later)\n",
    "    \"\"\"\n",
    "    # These helpers are expected from Block 2\n",
    "    concepts_txt = format_ontology_concepts(ontology_json)\n",
    "    relations_txt = format_ontology_relations(ontology_json)\n",
    "\n",
    "    prompt = f\"\"\"System\n",
    "You are a KG triple proposer in a Tree-of-Thoughts loop. First detect entity mentions and assign tentative ontology types. Then, using those mentions, propose candidate triples that are valid under the ontology (domain→range). Return only JSON.\n",
    "\n",
    "User\n",
    "Task: From the text, 1) list detected mentions with tentative types, 2) propose up to k={k} candidate triples [subject, relation, object].\n",
    "Use only relations whose domain/range match the types you inferred. For each triple, include confidence ∈ [0,1] and cite the exact supporting span(s).\n",
    "\n",
    "Text\n",
    "\"{_escape_multiline(test_sentence)}\"\n",
    "\n",
    "Ontology concepts\n",
    "{concepts_txt}\n",
    "\n",
    "Ontology relations (domain → range)\n",
    "{relations_txt}\n",
    "\n",
    "Output format (JSON only)\n",
    "{{\n",
    "  \"mentions\": [\n",
    "    {{\"surface\": \"...\", \"type_candidates\": [\"ConceptA\",\"ConceptB\"], \"span\": [start,end]}}\n",
    "  ],\n",
    "  \"triples\": [\n",
    "    {{\n",
    "      \"triple\": [\"subject\",\"relation\",\"object\"],\n",
    "      \"subject_type\": \"ConceptA\",   // required for evaluator Ontology\n",
    "      \"object_type\": \"ConceptB\",    // required for evaluator Ontology\n",
    "      \"confidence_prompt\": 0.0,     // rename from 'confidence'\n",
    "      \"support\": [\n",
    "        {{\"quote\": \"exact substring from text\", \"char_span\": [start,end]}}\n",
    "      ],\n",
    "      \"notes\": \"why domain/range fits; any pronoun/coref resolution; date normalization, etc.\",\n",
    "      \"ontology_domain_range_check\": true  // model may set; we'll recompute deterministically later\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Constraints\n",
    "- Only output domain/range-valid triples.\n",
    "- Provide at least one support quote with char_span; support.quote MUST be an exact substring of the text.\n",
    "- Normalize dates to YYYY-MM-DD when possible.\n",
    "- If a pronoun is required, resolve it to the nearest valid antecedent and describe it in notes.\n",
    "- Do not invent entities not in the text. Omit triples that are not explicitly supported.\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d2fe811-d1b5-4dea-88eb-48d28231289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 4 — Single Inference (chat template; continuation-only)\n",
    "\n",
    "def generate_json_text(generator, tokenizer, prompt_text: str,\n",
    "                       max_new_tokens: int = 768, temperature: float = 0.25) -> str:\n",
    "    \"\"\"\n",
    "    Calls the model once. Returns the generated continuation (string).\n",
    "    \"\"\"\n",
    "    chat = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a precise information-extraction model. Follow instructions carefully and return only JSON.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt_text}\n",
    "    ]\n",
    "    formatted = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    out = generator(\n",
    "        formatted,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=0.9,\n",
    "        do_sample=True,\n",
    "        return_full_text=False,\n",
    "        truncation=False,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return out[0][\"generated_text\"] if isinstance(out[0], dict) else out[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf943b7-0bd0-4610-8d43-ea6849860e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5 — Prompt 1 Parser & Post-Validation (spans, domain/range, dedupe, schema normalization)\n",
    "\n",
    "from typing import Dict, Any, List, Tuple\n",
    "import json\n",
    "import re\n",
    "\n",
    "def _support_is_substring(text: str, quote: str) -> bool:\n",
    "    return quote and quote in text\n",
    "\n",
    "def _span_ok(text: str, span: List[int], quote: str) -> bool:\n",
    "    if not span or len(span) != 2:\n",
    "        return False\n",
    "    s, e = span\n",
    "    if s < 0 or e < 0 or s >= e or e > len(text):\n",
    "        return False\n",
    "    return text[s:e] == quote\n",
    "\n",
    "def _ensure_surface_span_consistent(text: str, parsed: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    If mention spans are missing but surfaces exist, try to fill spans via exact match.\n",
    "    \"\"\"\n",
    "    for m in parsed.get(\"mentions\", []):\n",
    "        surf = m.get(\"surface\") or \"\"\n",
    "        span = m.get(\"span\")\n",
    "        if not surf:\n",
    "            continue\n",
    "        if not span or not isinstance(span, list) or len(span) != 2:\n",
    "            start = text.find(surf)\n",
    "            if start >= 0:\n",
    "                m[\"span\"] = [start, start + len(surf)]\n",
    "    return parsed\n",
    "\n",
    "def build_relation_sig_maps(ontology_json: Dict[str, Any]) -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    returns: {\"relation\": {\"domain\": \"ConceptA\", \"range\": \"ConceptB\"}}\n",
    "    \"\"\"\n",
    "    relsig = {}\n",
    "    rels = ontology_json.get(\"relations\") or ontology_json.get(\"Relations\") or []\n",
    "    for r in rels:\n",
    "        name = r.get(\"name\") or r.get(\"relation\") or r.get(\"label\")\n",
    "        dom  = r.get(\"domain\")\n",
    "        rng  = r.get(\"range\")\n",
    "        if name and dom and rng:\n",
    "            relsig[str(name)] = {\"domain\": str(dom), \"range\": str(rng)}\n",
    "    return relsig\n",
    "\n",
    "def _domain_range_valid(triple_obj: Dict[str, Any], relsig: Dict[str, Dict[str,str]]) -> bool:\n",
    "    t = triple_obj.get(\"triple\") or [\"\", \"\", \"\"]\n",
    "    rel = t[1] if len(t) == 3 else \"\"\n",
    "    st  = triple_obj.get(\"subject_type\") or \"\"\n",
    "    ot  = triple_obj.get(\"object_type\") or \"\"\n",
    "    sig = relsig.get(rel, {})\n",
    "    return bool(sig) and (st == sig.get(\"domain\")) and (ot == sig.get(\"range\"))\n",
    "\n",
    "def _index_mentions(parsed: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:\n",
    "    idx = {}\n",
    "    for m in parsed.get(\"mentions\", []):\n",
    "        s = (m.get(\"surface\") or \"\").strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        idx.setdefault(s, m)\n",
    "    return idx\n",
    "\n",
    "def _dedupe_triples(parsed: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    seen = set()\n",
    "    new = []\n",
    "    for t in parsed.get(\"triples\", []):\n",
    "        k = tuple(t.get(\"triple\") or [])\n",
    "        if len(k) != 3:\n",
    "            continue\n",
    "        if k in seen:\n",
    "            continue\n",
    "        seen.add(k)\n",
    "        new.append(t)\n",
    "    parsed[\"triples\"] = new\n",
    "    return parsed\n",
    "\n",
    "def parse_prompt1_json(raw: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Be forgiving about minor format deviations; normalize to evaluator-ready schema.\n",
    "    - rename 'confidence' -> 'confidence_prompt'\n",
    "    - coerce support into list of {quote, char_span}\n",
    "    - ensure subject_type/object_type keys exist (even if empty)\n",
    "    - drop triples with missing evidence quotes or bad spans\n",
    "    \"\"\"\n",
    "    try:\n",
    "        obj = json.loads(raw)\n",
    "    except Exception:\n",
    "        # try to recover code block content\n",
    "        m = re.search(r\"\\{[\\s\\S]*\\}\", raw)\n",
    "        obj = json.loads(m.group(0)) if m else {\"mentions\": [], \"triples\": []}\n",
    "\n",
    "    obj.setdefault(\"mentions\", [])\n",
    "    obj.setdefault(\"triples\", [])\n",
    "\n",
    "    # normalize triple entries\n",
    "    for t in obj[\"triples\"]:\n",
    "        # rename confidence\n",
    "        if \"confidence_prompt\" not in t and \"confidence\" in t:\n",
    "            t[\"confidence_prompt\"] = t.pop(\"confidence\")\n",
    "        t.setdefault(\"confidence_prompt\", 0.0)\n",
    "\n",
    "        # normalize support: allow string or list; convert to list of {quote, char_span}\n",
    "        sup = t.get(\"support\")\n",
    "        if isinstance(sup, str):\n",
    "            t[\"support\"] = [{\"quote\": sup, \"char_span\": []}]\n",
    "        elif isinstance(sup, list):\n",
    "            new_sup = []\n",
    "            for s in sup:\n",
    "                if isinstance(s, dict) and \"quote\" in s:\n",
    "                    s.setdefault(\"char_span\", [])\n",
    "                    new_sup.append(s)\n",
    "                elif isinstance(s, str):\n",
    "                    new_sup.append({\"quote\": s, \"char_span\": []})\n",
    "            t[\"support\"] = new_sup\n",
    "        else:\n",
    "            t[\"support\"] = []\n",
    "\n",
    "        # ensure types/flags exist\n",
    "        t.setdefault(\"subject_type\", \"\")\n",
    "        t.setdefault(\"object_type\", \"\")\n",
    "        t.setdefault(\"notes\", \"\")\n",
    "        t.setdefault(\"ontology_domain_range_check\", False)\n",
    "\n",
    "    return obj\n",
    "\n",
    "def post_validate_prompt1(\n",
    "    text: str,\n",
    "    parsed: Dict[str, Any],\n",
    "    ontology_json: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Enforce evaluator readiness:\n",
    "      - support.quote must be exact substring\n",
    "      - if char_span present, it must match quote\n",
    "      - recompute ontology_domain_range_check deterministically\n",
    "      - drop triples that fail any rule\n",
    "    \"\"\"\n",
    "    relsig = build_relation_sig_maps(ontology_json)\n",
    "\n",
    "    # fix mentions spans opportunistically\n",
    "    parsed = _ensure_surface_span_consistent(text, parsed)\n",
    "\n",
    "    kept = []\n",
    "    for t in parsed.get(\"triples\", []):\n",
    "        triple = t.get(\"triple\") or []\n",
    "        if len(triple) != 3:\n",
    "            continue\n",
    "\n",
    "        # evidence check\n",
    "        supports = t.get(\"support\") or []\n",
    "        if not supports:\n",
    "            continue\n",
    "\n",
    "        ok_ev = True\n",
    "        for s in supports:\n",
    "            quote = s.get(\"quote\") or \"\"\n",
    "            span  = s.get(\"char_span\") or []\n",
    "            if not _support_is_substring(text, quote):\n",
    "                ok_ev = False\n",
    "                break\n",
    "            if span:\n",
    "                if not _span_ok(text, span, quote):\n",
    "                    ok_ev = False\n",
    "                    break\n",
    "        if not ok_ev:\n",
    "            continue\n",
    "\n",
    "        # ontology check (deterministic)\n",
    "        t[\"ontology_domain_range_check\"] = _domain_range_valid(t, relsig)\n",
    "\n",
    "        # keep only ontology-valid triples\n",
    "        if not t[\"ontology_domain_range_check\"]:\n",
    "            continue\n",
    "\n",
    "        kept.append(t)\n",
    "\n",
    "    parsed[\"triples\"] = kept\n",
    "    parsed = _dedupe_triples(parsed)\n",
    "    return parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f7cb4a-46de-4d11-ab43-76cda7a98ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6 — Orchestrator (Prompt 1 end-to-end, zero-shot, with full debugging)\n",
    "\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "import json\n",
    "\n",
    "# Priority keys we will try to pull the input text from\n",
    "_TEXT_KEYS_PRIORITY = (\n",
    "    \"text\", \"Text\", \"sentence\", \"Sentence\", \"input\", \"Input\",\n",
    "    \"content\", \"document\", \"doc\", \"passage\", \"article\", \"context\",\n",
    "    \"raw_text\", \"body\", \"body_text\", \"main_text\", \"wiki_text\"\n",
    ")\n",
    "\n",
    "def _extract_text_field(rec: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Try multiple common keys to fetch the input text.\n",
    "    Returns (text, key_used). If none match, falls back to the longest string-valued field (>= 10 chars).\n",
    "    \"\"\"\n",
    "    for k in _TEXT_KEYS_PRIORITY:\n",
    "        val = rec.get(k)\n",
    "        if isinstance(val, str) and val.strip():\n",
    "            return val.strip(), k\n",
    "    # Fallback: pick the longest string field >= 10 chars\n",
    "    longest_key = None\n",
    "    longest_text = \"\"\n",
    "    for k, v in rec.items():\n",
    "        if isinstance(v, str) and len(v.strip()) >= 10 and len(v) > len(longest_text):\n",
    "            longest_text = v.strip()\n",
    "            longest_key = k\n",
    "    return (longest_text, longest_key or \"\")\n",
    "\n",
    "def run_pipeline_prompt1(\n",
    "    input_jsonl_path: str,\n",
    "    ontology_json_path: str,\n",
    "    output_jsonl_path: str,\n",
    "    max_items: Optional[int] = None,\n",
    "    max_new_tokens: int = 768,\n",
    "    temperature: float = 0.25,\n",
    "    verbose: bool = True,\n",
    "    k: int = 6,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Orchestrates Prompt 1 (zero-shot):\n",
    "      - loads ontology and inputs\n",
    "      - builds Prompt 1 instruction (no few-shots)\n",
    "      - calls the model (Block 4: generate_json_text(generator, tokenizer, prompt_text, ...))\n",
    "      - parses and post-validates JSON to be evaluator-ready\n",
    "      - writes output JSONL with raw and validated objects\n",
    "\n",
    "    This version prints:\n",
    "      * the EXACT prompt sent to the model,\n",
    "      * the RAW model output string,\n",
    "      * the PARSED JSON,\n",
    "      * the POST-VALIDATED JSON (evaluator-ready),\n",
    "    before saving to disk.\n",
    "    \"\"\"\n",
    "    # Load ontology\n",
    "    with open(ontology_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        ontology_json = json.load(f)\n",
    "\n",
    "    # Load inputs\n",
    "    items = list(read_jsonl(input_jsonl_path, max_items=max_items))\n",
    "    if verbose:\n",
    "        print(f\"[RUN] Loaded {len(items)} input items from {input_jsonl_path}\")\n",
    "\n",
    "    # Setup model (Block 4): must return (generator, tokenizer)\n",
    "    generator, tokenizer = setup_model()\n",
    "\n",
    "    outputs: List[Dict[str, Any]] = []\n",
    "\n",
    "    for idx, rec in enumerate(items, start=1):\n",
    "        rid = str(rec.get(\"id\") or f\"item_{idx}\")\n",
    "        text, key_used = _extract_text_field(rec)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n[RUN] === ID={rid} ===\")\n",
    "            print(f\"[INFO] Text source key: {key_used!r}\")\n",
    "            if not text:\n",
    "                print(\"[WARN] No non-empty text found in typical keys; also failed longest-string fallback.\")\n",
    "\n",
    "        if not text:\n",
    "            out_rec = {\n",
    "                \"id\": rid,\n",
    "                \"input_text\": text,\n",
    "                \"prompt1_prompt\": \"\",\n",
    "                \"prompt1_raw\": \"{}\",\n",
    "                \"prompt1_parsed\": {\"mentions\": [], \"triples\": []},\n",
    "                \"prompt1_validated\": {\"mentions\": [], \"triples\": []},\n",
    "                \"error\": \"empty_input_text\"\n",
    "            }\n",
    "            outputs.append(out_rec)\n",
    "            continue\n",
    "\n",
    "        # Build prompt (Block 3)\n",
    "        prompt_text = build_prompt1_json_only(\n",
    "            ontology_json=ontology_json,\n",
    "            test_sentence=text,\n",
    "            k=k,\n",
    "        )\n",
    "\n",
    "        # === DEBUG: print the full prompt ===\n",
    "        print(\"\\n==== [DEBUG] FINAL PROMPT SENT TO MODEL ====\")\n",
    "        print(prompt_text)\n",
    "        print(\"==== [DEBUG] END PROMPT ====\\n\")\n",
    "\n",
    "        # Generate model output (Block 4 signature: (generator, tokenizer, prompt_text, ...))\n",
    "        try:\n",
    "            raw = generate_json_text(\n",
    "                generator,\n",
    "                tokenizer,\n",
    "                prompt_text,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Generation failed for ID={rid}: {e}\")\n",
    "            raw = \"{}\"\n",
    "\n",
    "        # === DEBUG: print raw model output ===\n",
    "        print(\"==== [DEBUG] RAW MODEL OUTPUT ====\")\n",
    "        print(raw)\n",
    "        print(\"==== [DEBUG] END RAW OUTPUT ====\\n\")\n",
    "\n",
    "        # Parse (Block 5)\n",
    "        try:\n",
    "            parsed = parse_prompt1_json(raw)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Parse failed for ID={rid}: {e}\")\n",
    "            parsed = {\"mentions\": [], \"triples\": []}\n",
    "\n",
    "        # === DEBUG: print parsed JSON ===\n",
    "        print(\"==== [DEBUG] PARSED JSON ====\")\n",
    "        try:\n",
    "            print(json.dumps(parsed, ensure_ascii=False, indent=2))\n",
    "        except Exception:\n",
    "            print(parsed)\n",
    "        print(\"==== [DEBUG] END PARSED ====\\n\")\n",
    "\n",
    "        # Post-validate for evaluator readiness (Block 5)\n",
    "        try:\n",
    "            validated = post_validate_prompt1(text, parsed, ontology_json)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Post-validate failed for ID={rid}: {e}\")\n",
    "            validated = {\"mentions\": [], \"triples\": []}\n",
    "\n",
    "        # === DEBUG: print validated JSON ===\n",
    "        print(\"==== [DEBUG] VALIDATED JSON (Evaluator-ready) ====\")\n",
    "        try:\n",
    "            print(json.dumps(validated, ensure_ascii=False, indent=2))\n",
    "        except Exception:\n",
    "            print(validated)\n",
    "        print(\"==== [DEBUG] END VALIDATED ====\\n\")\n",
    "\n",
    "        out_rec = {\n",
    "            \"id\": rid,\n",
    "            \"input_text\": text,\n",
    "            \"prompt1_prompt\": prompt_text,\n",
    "            \"prompt1_raw\": raw,\n",
    "            \"prompt1_parsed\": parsed,\n",
    "            \"prompt1_validated\": validated,\n",
    "        }\n",
    "        outputs.append(out_rec)\n",
    "\n",
    "    # Write results\n",
    "    write_jsonl(output_jsonl_path, outputs)\n",
    "    if verbose:\n",
    "        print(f\"[RUN] Done. Wrote {len(outputs)} records to: {output_jsonl_path}\")\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1acf410-cd3b-4c60-b882-c6e38bd41a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] First input record keys: ['id', 'sent']\n",
      "  - id: ont_1_movie_test_1\n",
      "  - sent: Bleach: Hell Verse (Japanese: BLEACH , Hepburn: BurÄ«chi Jigoku-Hen) is a 2010 Japanese animated film directed by Noriyu...\n",
      "[RUN] Loaded 1 input items from /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_text/ont_1_movie_test.jsonl\n",
      "⏳ Loading model: mistralai/Mistral-7B-Instruct-v0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846bf11b501145569e77f4bbbbc8e89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RUN] === ID=ont_1_movie_test_1 ===\n",
      "[INFO] Text source key: 'sent'\n",
      "\n",
      "==== [DEBUG] FINAL PROMPT SENT TO MODEL ====\n",
      "System\n",
      "You are a KG triple proposer in a Tree-of-Thoughts loop. First detect entity mentions and assign tentative ontology types. Then, using those mentions, propose candidate triples that are valid under the ontology (domain→range). Return only JSON.\n",
      "\n",
      "User\n",
      "Task: From the text, 1) list detected mentions with tentative types, 2) propose up to k=6 candidate triples [subject, relation, object].\n",
      "Use only relations whose domain/range match the types you inferred. For each triple, include confidence ∈ [0,1] and cite the exact supporting span(s).\n",
      "\n",
      "Text\n",
      "\"Bleach: Hell Verse (Japanese: BLEACH , Hepburn: BurÄ«chi Jigoku-Hen) is a 2010 Japanese animated film directed by Noriyuki Abe.\"\n",
      "\n",
      "Ontology concepts\n",
      "human, city, country, film, film genre, genre, film production company, film award, award, written work, film character, film organization\n",
      "\n",
      "Ontology relations (domain → range)\n",
      "- director(film,human)\n",
      "- screenwriter(film,human)\n",
      "- genre(film,genre)\n",
      "- based on(film,written work)\n",
      "- cast member(film,human)\n",
      "- award received(film,award)\n",
      "- production company(film,film production company)\n",
      "- country of origin(film,country)\n",
      "- publication date(film,)\n",
      "- characters(film,film character)\n",
      "- narrative location(film,city)\n",
      "- filming location(film,city)\n",
      "- main subject(film,)\n",
      "- nominated for(film,award)\n",
      "- cost(film,)\n",
      "\n",
      "Output format (JSON only)\n",
      "{\n",
      "  \"mentions\": [\n",
      "    {\"surface\": \"...\", \"type_candidates\": [\"ConceptA\",\"ConceptB\"], \"span\": [start,end]}\n",
      "  ],\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"subject\",\"relation\",\"object\"],\n",
      "      \"subject_type\": \"ConceptA\",   // required for evaluator Ontology\n",
      "      \"object_type\": \"ConceptB\",    // required for evaluator Ontology\n",
      "      \"confidence_prompt\": 0.0,     // rename from 'confidence'\n",
      "      \"support\": [\n",
      "        {\"quote\": \"exact substring from text\", \"char_span\": [start,end]}\n",
      "      ],\n",
      "      \"notes\": \"why domain/range fits; any pronoun/coref resolution; date normalization, etc.\",\n",
      "      \"ontology_domain_range_check\": true  // model may set; we'll recompute deterministically later\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Constraints\n",
      "- Only output domain/range-valid triples.\n",
      "- Provide at least one support quote with char_span; support.quote MUST be an exact substring of the text.\n",
      "- Normalize dates to YYYY-MM-DD when possible.\n",
      "- If a pronoun is required, resolve it to the nearest valid antecedent and describe it in notes.\n",
      "- Do not invent entities not in the text. Omit triples that are not explicitly supported.\n",
      "\n",
      "==== [DEBUG] END PROMPT ====\n",
      "\n",
      "==== [DEBUG] RAW MODEL OUTPUT ====\n",
      " {\n",
      "  \"mentions\": [\n",
      "    {\n",
      "      \"surface\": \"Bleach: Hell Verse\",\n",
      "      \"type_candidates\": [\"film\"],\n",
      "      \"span\": [0, 17]\n",
      "    },\n",
      "    {\n",
      "      \"surface\": \"Noriyuki Abe\",\n",
      "      \"type_candidates\": [\"human\"],\n",
      "      \"span\": [36, 42]\n",
      "    },\n",
      "    {\n",
      "      \"surface\": \"Japanese\",\n",
      "      \"type_candidates\": [\"country\"],\n",
      "      \"span\": [18, 23]\n",
      "    }\n",
      "  ],\n",
      "  \"triples\": [\n",
      "    {\n",
      "      \"triple\": [\"Bleach: Hell Verse\", \"director\", \"Noriyuki Abe\"],\n",
      "      \"subject_type\": \"film\",\n",
      "      \"object_type\": \"human\",\n",
      "      \"confidence_prompt\": 1.0,\n",
      "      \"support\": [\n",
      "        {\n",
      "          \"quote\": \"directed by Noriyuki Abe\",\n",
      "          \"char_span\": [36, 48]\n",
      "        }\n",
      "      ],\n",
      "      \"notes\": \"The director relation fits as the text mentions Noriyuki Abe as the director of the film.\",\n",
      "      \"ontology_domain_range_check\": true\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Bleach: Hell Verse\", \"genre\", \"Hell Verse\"],\n",
      "      \"subject_type\": \"film\",\n",
      "      \"object_type\": \"genre\",\n",
      "      \"confidence_prompt\": 1.0,\n",
      "      \"support\": [\n",
      "        {\n",
      "          \"quote\": \"Bleach: Hell Verse\",\n",
      "          \"char_span\": [0, 17]\n",
      "        }\n",
      "      ],\n",
      "      \"notes\": \"The genre relation fits as the film's title is the same as the proposed genre.\",\n",
      "      \"ontology_domain_range_check\": true\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Bleach: Hell Verse\", \"country of origin\", \"Japanese\"],\n",
      "      \"subject_type\": \"film\",\n",
      "      \"object_type\": \"country\",\n",
      "      \"confidence_prompt\": 1.0,\n",
      "      \"support\": [\n",
      "        {\n",
      "          \"quote\": \"Japanese animated film\",\n",
      "          \"char_span\": [18, 30]\n",
      "        }\n",
      "      ],\n",
      "      \"notes\": \"The country of origin relation fits as the film is explicitly mentioned as being Japanese.\",\n",
      "      \"ontology_domain_range_check\": true\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Bleach: Hell Verse\", \"publication date\", \"2010\"],\n",
      "      \"subject_type\": \"film\",\n",
      "      \"object_type\": \"date\",\n",
      "      \"confidence_prompt\": 1.0,\n",
      "      \"support\": [\n",
      "        {\n",
      "          \"quote\": \"2010 Japanese animated film\",\n",
      "          \"char_span\": [18, 30]\n",
      "        }\n",
      "      ],\n",
      "      \"notes\": \"The publication date relation fits as the year is explicitly mentioned.\",\n",
      "      \"ontology_domain_range_check\": true\n",
      "    },\n",
      "    {\n",
      "      \"triple\": [\"Bleach: Hell Verse\", \"narrative location\", null],\n",
      "      \"subject_type\": \"film\",\n",
      "      \"object\n",
      "==== [DEBUG] END RAW OUTPUT ====\n",
      "\n",
      "[ERROR] Parse failed for ID=ont_1_movie_test_1: Expecting ',' delimiter: line 75 column 6 (char 2119)\n",
      "==== [DEBUG] PARSED JSON ====\n",
      "{\n",
      "  \"mentions\": [],\n",
      "  \"triples\": []\n",
      "}\n",
      "==== [DEBUG] END PARSED ====\n",
      "\n",
      "==== [DEBUG] VALIDATED JSON (Evaluator-ready) ====\n",
      "{\n",
      "  \"mentions\": [],\n",
      "  \"triples\": []\n",
      "}\n",
      "==== [DEBUG] END VALIDATED ====\n",
      "\n",
      "[RUN] Done. Wrote 1 records to: /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt1/wikidata/ont_1_movie_output_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Block 7 — Example Run (paths: replace with your actual ones)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Block 7 — Example Run (paths: replace with your actual ones; prints first record keys)\n",
    "\n",
    "# Paths — update to your filesystem\n",
    "ONTOLOGY_JSON = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/1_movie_ontology.json\"\n",
    "INPUT_JSONL   =  \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_text/ont_1_movie_test.jsonl\" \n",
    "OUTPUT_JSONL  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt1/wikidata/ont_1_movie_output_test.jsonl\" \n",
    "\n",
    "# Run parameters\n",
    "MAX_ITEMS       = 1        # keep 1 to make the debug printouts manageable\n",
    "MAX_NEW_TOKENS  = 768\n",
    "TEMPERATURE     = 0.25\n",
    "VERBOSE         = True\n",
    "K_CANDIDATES    = 6\n",
    "\n",
    "# Pre-flight: show keys of the first input record to confirm the text field name\n",
    "first = next(read_jsonl(INPUT_JSONL, max_items=1), None)\n",
    "if first is None:\n",
    "    print(f\"[ERROR] No records found in: {INPUT_JSONL}\")\n",
    "else:\n",
    "    print(\"[DEBUG] First input record keys:\", list(first.keys()))\n",
    "    # Also show a short preview of any string fields\n",
    "    for k, v in first.items():\n",
    "        if isinstance(v, str):\n",
    "            print(f\"  - {k}: {v[:120]}{'...' if len(v) > 120 else ''}\")\n",
    "\n",
    "# Execute pipeline (Block 6)\n",
    "_ = run_pipeline_prompt1(\n",
    "    input_jsonl_path=INPUT_JSONL,\n",
    "    ontology_json_path=ONTOLOGY_JSON,\n",
    "    output_jsonl_path=OUTPUT_JSONL,\n",
    "    max_items=MAX_ITEMS,\n",
    "    max_new_tokens=MAX_NEW_TOKENS,\n",
    "    temperature=TEMPERATURE,\n",
    "    verbose=VERBOSE,\n",
    "    k=K_CANDIDATES,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e977b5-883b-4b0a-94cf-73d3fc54e710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4acb6-41e7-4f32-a454-d196208cc635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_pipeline",
   "language": "python",
   "name": "kg_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
