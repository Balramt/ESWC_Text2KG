{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0b513-8c52-45cf-923f-846215422e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227321f-d650-4d7a-9a40-28ef53d55cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9d8c6-5e41-409f-80e7-548e69c96290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b6a0af14-15f3-4b01-b88c-098a9f57e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: imports & setup (no config stuff)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# ensure tokenizer is available\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except LookupError:\n",
    "    nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c5a1f1d7-6e01-4303-8533-677495cde579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CELL 2: base paths + filename lists (EDIT THESE) for prompt1\n",
    "\n",
    "# # ----- DBPEDIA -----\n",
    "# DBPEDIA_BASE_SYS  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt1/dbpedia/\"\n",
    "# DBPEDIA_BASE_GT   = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/\"\n",
    "# DBPEDIA_BASE_ONTO = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/\"\n",
    "# DBPEDIA_BASE_OUT  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt1/dbpedia/\"\n",
    "# DBPEDIA_AVG_FILE  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt1/dbpedia/eval_averages_prompt1.jsonl\"\n",
    "\n",
    "# DBPEDIA_FILENAMES = [\n",
    "# \t\t\"ont_1_university_output.jsonl\",\n",
    "# \t\t\"ont_2_musicalwork_output.jsonl\",\n",
    "# \t\t\"ont_3_airport_output.jsonl\",\n",
    "# \t\t\"ont_4_building_output.jsonl\",\n",
    "# \t\t\"ont_5_athlete_output.jsonl\",\n",
    "# \t\t\"ont_6_politician_output.jsonl\",\n",
    "# \t\t\"ont_7_company_output.jsonl\",\n",
    "# \t\t\"ont_8_celestialbody_output.jsonl\",\n",
    "# \t\t\"ont_9_astronaut_output.jsonl\",\n",
    "# \t\t\"ont_10_comicscharacter_output.jsonl\",\n",
    "# \t\t\"ont_11_meanoftransportation_output.jsonl\",\n",
    "# \t\t\"ont_12_monument_output.jsonl\",\n",
    "# \t\t\"ont_13_food_output.jsonl\",\n",
    "# \t\t\"ont_14_writtenwork_output.jsonl\",\n",
    "# \t\t\"ont_15_sportsteam_output.jsonl\",\n",
    "# \t\t\"ont_16_city_output.jsonl\",\n",
    "# \t\t\"ont_17_artist_output.jsonl\",\n",
    "# \t\t\"ont_18_scientist_output.jsonl\",\n",
    "# \t\t\"ont_19_film_output.jsonl\",\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# # ----- WIKIDATA -----\n",
    "# WIKI_BASE_SYS  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt1/wikidata/\"\n",
    "# WIKI_BASE_GT   = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/\"\n",
    "# WIKI_BASE_ONTO = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/\"\n",
    "# WIKI_BASE_OUT  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt1/wikidata/\"\n",
    "# WIKI_AVG_FILE  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt1/wikidata/eval_averages_prompt1.jsonl\"\n",
    "\n",
    "# WIKI_FILENAMES = [\n",
    "#         \"ont_1_movie_output.jsonl\",\n",
    "#         \"ont_2_music_output.jsonl\",\n",
    "#         \"ont_3_sport_output.jsonl\",\n",
    "#         \"ont_4_book_output.jsonl\",\n",
    "#         \"ont_5_military_output.jsonl\",\n",
    "#         \"ont_6_computer_output.jsonl\",\n",
    "#         \"ont_7_space_output.jsonl\",\n",
    "#         \"ont_8_politics_output.jsonl\",\n",
    "#         \"ont_9_nature_output.jsonl\",\n",
    "#         \"ont_10_culture_output.jsonl\",\n",
    "#     ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9f11297a-7ed3-4671-bdba-177dc9174232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CELL 2: base paths + filename lists (EDIT THESE) for prompt2\n",
    "\n",
    "# # ----- DBPEDIA -----\n",
    "# DBPEDIA_BASE_SYS  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt2/dbpedia/\"\n",
    "# DBPEDIA_BASE_GT   = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/\"\n",
    "# DBPEDIA_BASE_ONTO = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/\"\n",
    "# DBPEDIA_BASE_OUT  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt2/dbpedia/\"\n",
    "# DBPEDIA_AVG_FILE  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt2/dbpedia/eval_averages_prompt2.jsonl\"\n",
    "\n",
    "# DBPEDIA_FILENAMES = [\n",
    "# \t\t\"ont_1_university_output.jsonl\",\n",
    "# \t\t\"ont_2_musicalwork_output.jsonl\",\n",
    "# \t\t\"ont_3_airport_output.jsonl\",\n",
    "# \t\t\"ont_4_building_output.jsonl\",\n",
    "# \t\t\"ont_5_athlete_output.jsonl\",\n",
    "# \t\t\"ont_6_politician_output.jsonl\",\n",
    "# \t\t\"ont_7_company_output.jsonl\",\n",
    "# \t\t\"ont_8_celestialbody_output.jsonl\",\n",
    "# \t\t\"ont_9_astronaut_output.jsonl\",\n",
    "# \t\t\"ont_10_comicscharacter_output.jsonl\",\n",
    "# \t\t\"ont_11_meanoftransportation_output.jsonl\",\n",
    "# \t\t\"ont_12_monument_output.jsonl\",\n",
    "# \t\t\"ont_13_food_output.jsonl\",\n",
    "# \t\t\"ont_14_writtenwork_output.jsonl\",\n",
    "# \t\t\"ont_15_sportsteam_output.jsonl\",\n",
    "# \t\t\"ont_16_city_output.jsonl\",\n",
    "# \t\t\"ont_17_artist_output.jsonl\",\n",
    "# \t\t\"ont_18_scientist_output.jsonl\",\n",
    "# \t\t\"ont_19_film_output.jsonl\",\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# # ----- WIKIDATA -----\n",
    "# WIKI_BASE_SYS  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt2/wikidata/\"\n",
    "# WIKI_BASE_GT   = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/\"\n",
    "# WIKI_BASE_ONTO = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/\"\n",
    "# WIKI_BASE_OUT  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt2/wikidata/\"\n",
    "# WIKI_AVG_FILE  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt2/wikidata/eval_averages_prompt2.jsonl\"\n",
    "\n",
    "# WIKI_FILENAMES = [\n",
    "#         \"ont_1_movie_output.jsonl\",\n",
    "#         \"ont_2_music_output.jsonl\",\n",
    "#         \"ont_3_sport_output.jsonl\",\n",
    "#         \"ont_4_book_output.jsonl\",\n",
    "#         \"ont_5_military_output.jsonl\",\n",
    "#         \"ont_6_computer_output.jsonl\",\n",
    "#         \"ont_7_space_output.jsonl\",\n",
    "#         \"ont_8_politics_output.jsonl\",\n",
    "#         \"ont_9_nature_output.jsonl\",\n",
    "#         \"ont_10_culture_output.jsonl\",\n",
    "#     ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9b4ac898-bcce-4eab-981b-d5ec85fd0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: base paths + filename lists (EDIT THESE) for prompt3\n",
    "\n",
    "# ----- DBPEDIA -----\n",
    "DBPEDIA_BASE_SYS  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/\"\n",
    "DBPEDIA_BASE_GT   = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/\"\n",
    "DBPEDIA_BASE_ONTO = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/\"\n",
    "DBPEDIA_BASE_OUT  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/\"\n",
    "DBPEDIA_AVG_FILE  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/eval_averages_prompt3.jsonl\"\n",
    "\n",
    "DBPEDIA_FILENAMES = [\n",
    "\t\t\"ont_1_university_output.jsonl\",\n",
    "\t\t\"ont_2_musicalwork_output.jsonl\",\n",
    "\t\t\"ont_3_airport_output.jsonl\",\n",
    "\t\t\"ont_4_building_output.jsonl\",\n",
    "\t\t\"ont_5_athlete_output.jsonl\",\n",
    "\t\t\"ont_6_politician_output.jsonl\",\n",
    "\t\t\"ont_7_company_output.jsonl\",\n",
    "\t\t\"ont_8_celestialbody_output.jsonl\",\n",
    "\t\t\"ont_9_astronaut_output.jsonl\",\n",
    "\t\t\"ont_10_comicscharacter_output.jsonl\",\n",
    "\t\t\"ont_11_meanoftransportation_output.jsonl\",\n",
    "\t\t\"ont_12_monument_output.jsonl\",\n",
    "\t\t\"ont_13_food_output.jsonl\",\n",
    "\t\t\"ont_14_writtenwork_output.jsonl\",\n",
    "\t\t\"ont_15_sportsteam_output.jsonl\",\n",
    "\t\t\"ont_16_city_output.jsonl\",\n",
    "\t\t\"ont_17_artist_output.jsonl\",\n",
    "\t\t\"ont_18_scientist_output.jsonl\",\n",
    "\t\t\"ont_19_film_output.jsonl\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# ----- WIKIDATA -----\n",
    "WIKI_BASE_SYS  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/wikidata/\"\n",
    "WIKI_BASE_GT   = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/\"\n",
    "WIKI_BASE_ONTO = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/\"\n",
    "WIKI_BASE_OUT  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/\"\n",
    "WIKI_AVG_FILE  = \"/upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/eval_averages_prompt3.jsonl\"\n",
    "\n",
    "WIKI_FILENAMES = [\n",
    "        \"ont_1_movie_output.jsonl\",\n",
    "        \"ont_2_music_output.jsonl\",\n",
    "        \"ont_3_sport_output.jsonl\",\n",
    "        \"ont_4_book_output.jsonl\",\n",
    "        \"ont_5_military_output.jsonl\",\n",
    "        \"ont_6_computer_output.jsonl\",\n",
    "        \"ont_7_space_output.jsonl\",\n",
    "        \"ont_8_politics_output.jsonl\",\n",
    "        \"ont_9_nature_output.jsonl\",\n",
    "        \"ont_10_culture_output.jsonl\",\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "eb144438-ba5a-482f-93a6-00165251bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: json/jsonl helpers\n",
    "\n",
    "def read_json(path: str) -> Dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def read_jsonl(path: str, is_json: bool = True) -> List:\n",
    "    items = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            items.append(json.loads(line) if is_json else line)\n",
    "    return items\n",
    "\n",
    "\n",
    "def save_jsonl(items: List, path: str) -> None:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for it in items:\n",
    "            f.write(json.dumps(it, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def append_jsonl(item: Dict, path: str) -> None:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"a+\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8f453ece-4ab7-482d-84aa-095e0073ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_system_triples_from_record(sys_record: dict) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Extract triples from your LLM output structure.\n",
    "\n",
    "    Works for lines like the ones you just shared. Also defends against:\n",
    "    - response = null\n",
    "    - response.json missing\n",
    "    - triples = not a list\n",
    "    - triple entries that don't have exactly 3 strings\n",
    "    \"\"\"\n",
    "    # 1) must be a dict\n",
    "    if not isinstance(sys_record, dict):\n",
    "        return []\n",
    "\n",
    "    # 2) get response\n",
    "    resp = sys_record.get(\"response\")\n",
    "    if not isinstance(resp, dict):\n",
    "        return []\n",
    "\n",
    "    # 3) get parsed json part\n",
    "    resp_json = resp.get(\"json\")\n",
    "    if not isinstance(resp_json, dict):\n",
    "        return []\n",
    "\n",
    "    # 4) get triples array\n",
    "    triples_block = resp_json.get(\"triples\")\n",
    "    if not isinstance(triples_block, list):\n",
    "        return []\n",
    "\n",
    "    cleaned: list[list[str]] = []\n",
    "\n",
    "    for item in triples_block:\n",
    "        # normal, good case: {\"triple\": [\"sub\", \"rel\", \"obj\"], ...}\n",
    "        if isinstance(item, dict) and \"triple\" in item:\n",
    "            t = item[\"triple\"]\n",
    "        else:\n",
    "            # fallback: maybe it was directly a list\n",
    "            t = item\n",
    "\n",
    "        # we only accept lists of exactly 3 strings\n",
    "        if (\n",
    "            isinstance(t, list)\n",
    "            and len(t) == 3\n",
    "            and all(isinstance(x, str) for x in t)\n",
    "        ):\n",
    "            cleaned.append(t)\n",
    "        # else: ignore malformed triple\n",
    "\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6a4fec8b-5347-46da-a3b4-c13ff3b2d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: metrics & normalization\n",
    "\n",
    "def normalize_triple(sub: str, rel: str, obj: str) -> str:\n",
    "    sub = re.sub(r\"(_|\\s+)\", \"\", sub).lower()\n",
    "    rel = re.sub(r\"(_|\\s+)\", \"\", rel).lower()\n",
    "    obj = re.sub(r\"(_|\\s+)\", \"\", obj).lower()\n",
    "    return f\"{sub}{rel}{obj}\"\n",
    "\n",
    "\n",
    "def calculate_precision_recall_f1(gold: set, pred: set) -> Tuple[float, float, float]:\n",
    "    if len(pred) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    correct = len(gold & pred)\n",
    "    p = correct / len(pred)\n",
    "    r = correct / len(gold)\n",
    "    f1 = 2 * p * r / (p + r) if (p + r) > 0 else 0.0\n",
    "    return p, r, f1\n",
    "\n",
    "\n",
    "def clean_entity_string(ps: PorterStemmer, entity: str) -> str:\n",
    "    stemmed = \"\".join(ps.stem(tok) for tok in word_tokenize(entity))\n",
    "    norm = re.sub(r\"(_|\\s+)\", \"\", stemmed).lower()\n",
    "    return norm.replace(\"01januari\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fc2b54ed-35a7-4d02-b946-93d26bc9c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: ontology metrics (same as original)\n",
    "\n",
    "def get_ontology_conformance(ontology: Dict, triples: List[List[str]]) -> Tuple[float, float]:\n",
    "    if not triples:\n",
    "        return 1.0, 0.0\n",
    "    ont_rels = [r[\"label\"].replace(\" \", \"_\") for r in ontology[\"relations\"]]\n",
    "    ok = len([tr for tr in triples if tr[1] in ont_rels])\n",
    "    conf = ok / len(triples)\n",
    "    return conf, 1 - conf\n",
    "\n",
    "\n",
    "def get_subject_object_hallucinations(\n",
    "    ps: PorterStemmer,\n",
    "    ontology: Dict,\n",
    "    sentence: str,\n",
    "    triples: List[List[str]]\n",
    ") -> Tuple[float, float]:\n",
    "    if not triples:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    # sentence + ontology concepts\n",
    "    context = sentence + \" \" + \" \".join(c[\"label\"] for c in ontology[\"concepts\"])\n",
    "    stemmed = \"\".join(ps.stem(tok) for tok in word_tokenize(context))\n",
    "    norm_ctx = re.sub(r\"(_|\\s+)\", \"\", stemmed).lower()\n",
    "\n",
    "    sub_h = 0\n",
    "    obj_h = 0\n",
    "    for sub, _, obj in triples:\n",
    "        sub_c = clean_entity_string(ps, sub)\n",
    "        obj_c = clean_entity_string(ps, obj)\n",
    "        if norm_ctx.find(sub_c) == -1:\n",
    "            sub_h += 1\n",
    "        if norm_ctx.find(obj_c) == -1:\n",
    "            obj_h += 1\n",
    "\n",
    "    total = len(triples)\n",
    "    return sub_h / total, obj_h / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "43e7af44-217c-4a0a-ad30-eb938e9a50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "# now match ..._output.jsonl (not ..._test.jsonl)\n",
    "DBPEDIA_PATTERN  = re.compile(r\"^ont_(\\d+)_([a-zA-Z0-9]+)_output\\.jsonl$\")\n",
    "WIKIDATA_PATTERN = re.compile(r\"^ont_(\\d+)_([a-zA-Z0-9]+)_output\\.jsonl$\")\n",
    "\n",
    "\n",
    "def make_dbpedia_paths(filename: str) -> Tuple[str, str, str, str, str]:\n",
    "    \"\"\"\n",
    "    Example:\n",
    "      filename:  ont_12_monument_output.jsonl\n",
    "      returns:\n",
    "        sys   = <DBPEDIA_BASE_SYS>/ont_12_monument_output.jsonl\n",
    "        gt    = <DBPEDIA_BASE_GT>/ont_12_monument_ground_truth.jsonl\n",
    "        onto  = <DBPEDIA_BASE_ONTO>/12_monument_ontology.json\n",
    "        out   = <DBPEDIA_BASE_OUT>/ont_12_monument_eval_sentences.jsonl\n",
    "        tag   = \"ont_12_monument\"\n",
    "    \"\"\"\n",
    "    m = DBPEDIA_PATTERN.match(filename)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unexpected DBpedia filename: {filename}\")\n",
    "    idx, cat = m.groups()\n",
    "    tag = f\"ont_{idx}_{cat}\"\n",
    "\n",
    "    sys_path  = os.path.join(DBPEDIA_BASE_SYS, filename)\n",
    "    gt_path   = os.path.join(DBPEDIA_BASE_GT, f\"{tag}_ground_truth.jsonl\")\n",
    "    onto_path = os.path.join(DBPEDIA_BASE_ONTO, f\"{idx}_{cat}_ontology.json\")\n",
    "    out_path  = os.path.join(DBPEDIA_BASE_OUT, f\"{tag}_eval_sentences.jsonl\")\n",
    "    return sys_path, gt_path, onto_path, out_path, tag\n",
    "\n",
    "\n",
    "def make_wikidata_paths(filename: str) -> Tuple[str, str, str, str, str]:\n",
    "    \"\"\"\n",
    "    Example:\n",
    "      filename:  ont_1_movie_output.jsonl\n",
    "      returns:\n",
    "        sys   = <WIKI_BASE_SYS>/ont_1_movie_output.jsonl\n",
    "        gt    = <WIKI_BASE_GT>/ont_1_movie_ground_truth.jsonl\n",
    "        onto  = <WIKI_BASE_ONTO>/1_movie_ontology.json\n",
    "        out   = <WIKI_BASE_OUT>/ont_1_movie_eval_sentences.jsonl\n",
    "        tag   = \"ont_1_movie\"\n",
    "    \"\"\"\n",
    "    m = WIKIDATA_PATTERN.match(filename)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unexpected Wikidata filename: {filename}\")\n",
    "    idx, cat = m.groups()\n",
    "    tag = f\"ont_{idx}_{cat}\"\n",
    "\n",
    "    sys_path  = os.path.join(WIKI_BASE_SYS, filename)\n",
    "    gt_path   = os.path.join(WIKI_BASE_GT, f\"{tag}_ground_truth.jsonl\")\n",
    "    onto_path = os.path.join(WIKI_BASE_ONTO, f\"{idx}_{cat}_ontology.json\")\n",
    "    out_path  = os.path.join(WIKI_BASE_OUT, f\"{tag}_eval_sentences.jsonl\")\n",
    "    return sys_path, gt_path, onto_path, out_path, tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "26e2b9dd-3f30-4836-86af-0bd8e08fc0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8: evaluate ONE ontology/file (no config)\n",
    "\n",
    "def evaluate_one_file(\n",
    "    sys_path: str,\n",
    "    gt_path: str,\n",
    "    onto_path: str,\n",
    "    out_path: str,\n",
    "    avg_out_file: str,\n",
    "    tag: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Core evaluation logic (same as big script) but for ONE file, with explicit paths.\n",
    "    \"\"\"\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    system_list = read_jsonl(sys_path)\n",
    "    gt_list = read_jsonl(gt_path)\n",
    "    ontology = read_json(onto_path)\n",
    "\n",
    "    system_by_id = {rec[\"id\"]: rec for rec in system_list if \"id\" in rec}\n",
    "    gt_by_id = {rec[\"id\"]: rec for rec in gt_list if \"id\" in rec}\n",
    "\n",
    "    t_p = t_r = t_f1 = 0.0\n",
    "    t_onto = t_rel_h = 0.0\n",
    "    t_sub_h = t_obj_h = 0.0\n",
    "\n",
    "    per_sent = []\n",
    "\n",
    "    for sent_id, gt_rec in gt_by_id.items():\n",
    "        gt_triples = [[tr[\"sub\"], tr[\"rel\"], tr[\"obj\"]] for tr in gt_rec[\"triples\"]]\n",
    "        sentence = gt_rec.get(\"sent\", \"\")\n",
    "\n",
    "        if sent_id not in system_by_id:\n",
    "            continue\n",
    "\n",
    "        sys_rec = system_by_id[sent_id]\n",
    "        sys_triples = extract_system_triples_from_record(sys_rec)\n",
    "\n",
    "        # filter by gold relations (same as original evaluator)\n",
    "        gold_rels = {tr[1].replace(\" \", \"_\") for tr in gt_triples}\n",
    "        sys_triples_f = [tr for tr in sys_triples if tr[1] in gold_rels]\n",
    "\n",
    "        # normalize for P/R/F1\n",
    "        norm_sys = {normalize_triple(*tr) for tr in sys_triples_f}\n",
    "        norm_gt = {normalize_triple(*tr) for tr in gt_triples}\n",
    "\n",
    "        p, r, f1 = calculate_precision_recall_f1(norm_gt, norm_sys)\n",
    "        onto_conf, rel_halluc = get_ontology_conformance(ontology, sys_triples)\n",
    "        sub_h, obj_h = get_subject_object_hallucinations(ps, ontology, sentence, sys_triples)\n",
    "\n",
    "        per_sent.append({\n",
    "            \"id\": sent_id,\n",
    "            \"precision\": f\"{p:.2f}\",\n",
    "            \"recall\": f\"{r:.2f}\",\n",
    "            \"f1\": f\"{f1:.2f}\",\n",
    "            \"onto_conf\": f\"{onto_conf:.2f}\",\n",
    "            \"rel_halluc\": f\"{rel_halluc:.2f}\",\n",
    "            \"sub_halluc\": f\"{sub_h:.2f}\",\n",
    "            \"obj_halluc\": f\"{obj_h:.2f}\",\n",
    "            \"llm_triples\": sys_triples,\n",
    "            \"filtered_llm_triples\": sys_triples_f,\n",
    "            \"gt_triples\": gt_triples,\n",
    "            \"sent\": sentence,\n",
    "        })\n",
    "\n",
    "        t_p += p\n",
    "        t_r += r\n",
    "        t_f1 += f1\n",
    "        t_onto += onto_conf\n",
    "        t_rel_h += rel_halluc\n",
    "        t_sub_h += sub_h\n",
    "        t_obj_h += obj_h\n",
    "\n",
    "    # write per-sentence eval\n",
    "    save_jsonl(per_sent, out_path)\n",
    "\n",
    "    total = len(gt_by_id) if gt_by_id else 1\n",
    "    avg_metrics = {\n",
    "        \"onto\": tag,\n",
    "        \"type\": \"all_test_cases\",\n",
    "        \"avg_precision\": f\"{t_p / total:.2f}\",\n",
    "        \"avg_recall\": f\"{t_r / total:.2f}\",\n",
    "        \"avg_f1\": f\"{t_f1 / total:.2f}\",\n",
    "        \"avg_onto_conf\": f\"{t_onto / total:.2f}\",\n",
    "        \"avg_sub_halluc\": f\"{t_sub_h / total:.2f}\",\n",
    "        \"avg_rel_halluc\": f\"{t_rel_h / total:.2f}\",\n",
    "        \"avg_obj_halluc\": f\"{t_obj_h / total:.2f}\",\n",
    "    }\n",
    "    append_jsonl(avg_metrics, avg_out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "006df30a-c21d-4ec5-9793-2a2c95cc8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 9: batch runners (these replace run_evaluation(config))\n",
    "\n",
    "def run_dbpedia_eval_batch():\n",
    "    os.makedirs(DBPEDIA_BASE_OUT, exist_ok=True)\n",
    "\n",
    "        # ðŸ”´ IMPORTANT: start fresh so repeated runs don't append duplicates\n",
    "    if os.path.exists(DBPEDIA_AVG_FILE):\n",
    "        os.remove(DBPEDIA_AVG_FILE)\n",
    "\n",
    "\n",
    "    \n",
    "    for fname in DBPEDIA_FILENAMES:\n",
    "        try:\n",
    "            sys_path, gt_path, onto_path, out_path, tag = make_dbpedia_paths(fname)\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"[DBPEDIA] {tag}\")\n",
    "            print(f\"  sys  : {sys_path}\")\n",
    "            print(f\"  gt   : {gt_path}\")\n",
    "            print(f\"  onto : {onto_path}\")\n",
    "            print(f\"  out  : {out_path}\")\n",
    "            evaluate_one_file(\n",
    "                sys_path=sys_path,\n",
    "                gt_path=gt_path,\n",
    "                onto_path=onto_path,\n",
    "                out_path=out_path,\n",
    "                avg_out_file=DBPEDIA_AVG_FILE,\n",
    "                tag=tag,\n",
    "            )\n",
    "            print(f\"[DONE] {tag}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {fname}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f1348-290d-447f-a73f-bf98571347cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4c5ada60-2af6-41d1-ae91-4d9055591459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[DBPEDIA] ont_1_university\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_1_university_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_1_university_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/1_university_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_1_university_eval_sentences.jsonl\n",
      "[DONE] ont_1_university\n",
      "============================================================\n",
      "[DBPEDIA] ont_2_musicalwork\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_2_musicalwork_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_2_musicalwork_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/2_musicalwork_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_2_musicalwork_eval_sentences.jsonl\n",
      "[DONE] ont_2_musicalwork\n",
      "============================================================\n",
      "[DBPEDIA] ont_3_airport\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_3_airport_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_3_airport_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/3_airport_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_3_airport_eval_sentences.jsonl\n",
      "[DONE] ont_3_airport\n",
      "============================================================\n",
      "[DBPEDIA] ont_4_building\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_4_building_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_4_building_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/4_building_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_4_building_eval_sentences.jsonl\n",
      "[DONE] ont_4_building\n",
      "============================================================\n",
      "[DBPEDIA] ont_5_athlete\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_5_athlete_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_5_athlete_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/5_athlete_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_5_athlete_eval_sentences.jsonl\n",
      "[DONE] ont_5_athlete\n",
      "============================================================\n",
      "[DBPEDIA] ont_6_politician\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_6_politician_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_6_politician_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/6_politician_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_6_politician_eval_sentences.jsonl\n",
      "[DONE] ont_6_politician\n",
      "============================================================\n",
      "[DBPEDIA] ont_7_company\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_7_company_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_7_company_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/7_company_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_7_company_eval_sentences.jsonl\n",
      "[DONE] ont_7_company\n",
      "============================================================\n",
      "[DBPEDIA] ont_8_celestialbody\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_8_celestialbody_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_8_celestialbody_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/8_celestialbody_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_8_celestialbody_eval_sentences.jsonl\n",
      "[DONE] ont_8_celestialbody\n",
      "============================================================\n",
      "[DBPEDIA] ont_9_astronaut\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_9_astronaut_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_9_astronaut_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/9_astronaut_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_9_astronaut_eval_sentences.jsonl\n",
      "[DONE] ont_9_astronaut\n",
      "============================================================\n",
      "[DBPEDIA] ont_10_comicscharacter\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_10_comicscharacter_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_10_comicscharacter_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/10_comicscharacter_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_10_comicscharacter_eval_sentences.jsonl\n",
      "[DONE] ont_10_comicscharacter\n",
      "============================================================\n",
      "[DBPEDIA] ont_11_meanoftransportation\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_11_meanoftransportation_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_11_meanoftransportation_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/11_meanoftransportation_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_11_meanoftransportation_eval_sentences.jsonl\n",
      "[DONE] ont_11_meanoftransportation\n",
      "============================================================\n",
      "[DBPEDIA] ont_12_monument\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_12_monument_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_12_monument_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/12_monument_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_12_monument_eval_sentences.jsonl\n",
      "[DONE] ont_12_monument\n",
      "============================================================\n",
      "[DBPEDIA] ont_13_food\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_13_food_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_13_food_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/13_food_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_13_food_eval_sentences.jsonl\n",
      "[DONE] ont_13_food\n",
      "============================================================\n",
      "[DBPEDIA] ont_14_writtenwork\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_14_writtenwork_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_14_writtenwork_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/14_writtenwork_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_14_writtenwork_eval_sentences.jsonl\n",
      "[DONE] ont_14_writtenwork\n",
      "============================================================\n",
      "[DBPEDIA] ont_15_sportsteam\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_15_sportsteam_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_15_sportsteam_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/15_sportsteam_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_15_sportsteam_eval_sentences.jsonl\n",
      "[DONE] ont_15_sportsteam\n",
      "============================================================\n",
      "[DBPEDIA] ont_16_city\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_16_city_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_16_city_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/16_city_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_16_city_eval_sentences.jsonl\n",
      "[DONE] ont_16_city\n",
      "============================================================\n",
      "[DBPEDIA] ont_17_artist\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_17_artist_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_17_artist_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/17_artist_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_17_artist_eval_sentences.jsonl\n",
      "[DONE] ont_17_artist\n",
      "============================================================\n",
      "[DBPEDIA] ont_18_scientist\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_18_scientist_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_18_scientist_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/18_scientist_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_18_scientist_eval_sentences.jsonl\n",
      "[DONE] ont_18_scientist\n",
      "============================================================\n",
      "[DBPEDIA] ont_19_film\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/dbpedia/ont_19_film_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/ground_truth/ont_19_film_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/dbpedia/input_ontology/19_film_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/dbpedia/ont_19_film_eval_sentences.jsonl\n",
      "[DONE] ont_19_film\n"
     ]
    }
   ],
   "source": [
    "run_dbpedia_eval_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ec180-8bff-4052-975a-7a73896df97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "77313f91-3331-4766-aa42-078b79b5a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wikidata_eval_batch():\n",
    "    # make sure output dir exists\n",
    "    os.makedirs(WIKI_BASE_OUT, exist_ok=True)\n",
    "\n",
    "    # ðŸ”´ IMPORTANT: start fresh so repeated runs don't append duplicates\n",
    "    if os.path.exists(WIKI_AVG_FILE):\n",
    "        os.remove(WIKI_AVG_FILE)\n",
    "\n",
    "    for fname in WIKI_FILENAMES:\n",
    "        try:\n",
    "            sys_path, gt_path, onto_path, out_path, tag = make_wikidata_paths(fname)\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"[WIKIDATA] {tag}\")\n",
    "            print(f\"  sys  : {sys_path}\")\n",
    "            print(f\"  gt   : {gt_path}\")\n",
    "            print(f\"  onto : {onto_path}\")\n",
    "            print(f\"  out  : {out_path}\")\n",
    "            evaluate_one_file(\n",
    "                sys_path=sys_path,\n",
    "                gt_path=gt_path,\n",
    "                onto_path=onto_path,\n",
    "                out_path=out_path,\n",
    "                avg_out_file=WIKI_AVG_FILE,\n",
    "                tag=tag,\n",
    "            )\n",
    "            print(f\"[DONE] {tag}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {fname}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4b3a6e91-40d7-4dee-9c22-298d4d06e90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[WIKIDATA] ont_1_movie\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/wikidata/ont_1_movie_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/ont_1_movie_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/1_movie_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/ont_1_movie_eval_sentences.jsonl\n",
      "[DONE] ont_1_movie\n",
      "============================================================\n",
      "[WIKIDATA] ont_2_music\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/wikidata/ont_2_music_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/ont_2_music_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/2_music_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/ont_2_music_eval_sentences.jsonl\n",
      "[DONE] ont_2_music\n",
      "============================================================\n",
      "[WIKIDATA] ont_3_sport\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/wikidata/ont_3_sport_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/ont_3_sport_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/3_sport_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/ont_3_sport_eval_sentences.jsonl\n",
      "[DONE] ont_3_sport\n",
      "============================================================\n",
      "[WIKIDATA] ont_4_book\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/wikidata/ont_4_book_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/ont_4_book_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/4_book_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/ont_4_book_eval_sentences.jsonl\n",
      "[DONE] ont_4_book\n",
      "============================================================\n",
      "[WIKIDATA] ont_5_military\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/wikidata/ont_5_military_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/ont_5_military_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/5_military_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/ont_5_military_eval_sentences.jsonl\n",
      "[DONE] ont_5_military\n",
      "============================================================\n",
      "[WIKIDATA] ont_6_computer\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/wikidata/ont_6_computer_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/ont_6_computer_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/6_computer_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/ont_6_computer_eval_sentences.jsonl\n",
      "[DONE] ont_6_computer\n",
      "============================================================\n",
      "[WIKIDATA] ont_7_space\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/wikidata/ont_7_space_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/ont_7_space_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/7_space_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/ont_7_space_eval_sentences.jsonl\n",
      "[DONE] ont_7_space\n",
      "============================================================\n",
      "[WIKIDATA] ont_8_politics\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/wikidata/ont_8_politics_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/ont_8_politics_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/8_politics_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/ont_8_politics_eval_sentences.jsonl\n",
      "[DONE] ont_8_politics\n",
      "============================================================\n",
      "[WIKIDATA] ont_9_nature\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/wikidata/ont_9_nature_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/ont_9_nature_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/9_nature_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/ont_9_nature_eval_sentences.jsonl\n",
      "[DONE] ont_9_nature\n",
      "============================================================\n",
      "[WIKIDATA] ont_10_culture\n",
      "  sys  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/output/prompt3/wikidata/ont_10_culture_output.jsonl\n",
      "  gt   : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/ground_truth/ont_10_culture_ground_truth.jsonl\n",
      "  onto : /upb/users/b/balram/profiles/unix/cs/promptKG/data/input/wikidata/input_ontology/10_culture_ontology.json\n",
      "  out  : /upb/users/b/balram/profiles/unix/cs/promptKG/data/evaluation/prompt3/wikidata/ont_10_culture_eval_sentences.jsonl\n",
      "[DONE] ont_10_culture\n"
     ]
    }
   ],
   "source": [
    "run_wikidata_eval_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7806eb-4504-4460-a6ea-3718cc4c0ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_pipeline",
   "language": "python",
   "name": "kg_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
